{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c099915",
   "metadata": {
    "id": "6c099915"
   },
   "source": [
    "# Google Earth Engine Component"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b600c4",
   "metadata": {
    "id": "f1b600c4"
   },
   "source": [
    "## Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10a33a5d",
   "metadata": {
    "id": "10a33a5d"
   },
   "outputs": [],
   "source": [
    "#Import required libraries\n",
    "import os\n",
    "from time import time\n",
    "from pprint import pprint\n",
    "import math\n",
    "import itertools\n",
    "\n",
    "import ee\n",
    "import geemap\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.metrics import classification_report, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "import keras_tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07092838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-15 21:33:18.751536: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-15 21:33:18.761984: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-15 21:33:18.763914: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    }
   ],
   "source": [
    "# Check number of available GPUs\n",
    "n_gpus = len(tf.config.list_physical_devices('GPU'))\n",
    "assert n_gpus >= 1\n",
    "print(\"Num GPUs Available:\", n_gpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2bf9b8c4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2bf9b8c4",
    "outputId": "51de3b2c-7998-45eb-d39b-f0d307b84740"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p>To authorize access needed by Earth Engine, open the following\n",
       "        URL in a web browser and follow the instructions:</p>\n",
       "        <p><a href=https://code.earthengine.google.com/client-auth?scopes=https%3A//www.googleapis.com/auth/earthengine%20https%3A//www.googleapis.com/auth/devstorage.full_control&request_id=zhcBObMd-2ATEUR3kG8lfdt2Y2J2_0_BUkrQYrDxeTc&tc=gXs0r3cL6vbgiGfvzorRciJ85NPLj01RSn6QXFUMcEg&cc=RilGCLaUEn5nds5Bf5oIwO6zPSR8Xyjp2wQ4_nbhw98>https://code.earthengine.google.com/client-auth?scopes=https%3A//www.googleapis.com/auth/earthengine%20https%3A//www.googleapis.com/auth/devstorage.full_control&request_id=zhcBObMd-2ATEUR3kG8lfdt2Y2J2_0_BUkrQYrDxeTc&tc=gXs0r3cL6vbgiGfvzorRciJ85NPLj01RSn6QXFUMcEg&cc=RilGCLaUEn5nds5Bf5oIwO6zPSR8Xyjp2wQ4_nbhw98</a></p>\n",
       "        <p>The authorization workflow will generate a code, which you\n",
       "        should paste in the box below</p>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter verification code: 4/1AdQt8qi-z4UOcXRvi5F6ALu2xPBaiIFp5dCtbPhbvyxy48YeUdgPRlr-nN4\n",
      "\n",
      "Successfully saved authorization token.\n"
     ]
    }
   ],
   "source": [
    "#Initialize Google Earth Engine\n",
    "#just needed the 1st time\n",
    "ee.Authenticate() \n",
    "ee.Initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e5b42a",
   "metadata": {},
   "source": [
    "## Define Globals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b8b282e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17,
     "referenced_widgets": [
      "57521180d256424c974c1184813bf5f4"
     ]
    },
    "id": "0b8b282e",
    "outputId": "aff1cb3c-46b2-4025-f839-2007c003190e"
   },
   "outputs": [],
   "source": [
    "# Define classes\n",
    "CLASSES = ['water',\n",
    "           'vegetation_trees',\n",
    "           'vegetation_grass',\n",
    "           'turf',\n",
    "           'impervious',\n",
    "           'soil']\n",
    "\n",
    "N_CLASSES = len(CLASSES)\n",
    "\n",
    "# Define the label and bands\n",
    "LABEL = 'landcover'\n",
    "NBANDS = ['R', \n",
    "         'G', \n",
    "         'B', \n",
    "         'N', \n",
    "         'NDVI',\n",
    "         'N_Entropy', \n",
    "         'N_Contrast', \n",
    "         'N_Gearys']\n",
    "\n",
    "ALL_BANDS = NBANDS + ['R_Entropy',\n",
    "                      'R_Contrast',\n",
    "                      'R_Gearys',\n",
    "                      'G_Entropy',\n",
    "                      'G_Contrast',\n",
    "                      'G_Gearys',\n",
    "                      'B_Entropy',\n",
    "                      'B_Contrast',\n",
    "                      'B_Gearys']\n",
    "\n",
    "# Select desired band set\n",
    "BANDS = ALL_BANDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eaa55293",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7b4cad3f7e9422c92fde266f68d0536",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[20, 0], controls=(WidgetControl(options=['position', 'transparent_bg'], widget=HBox(children=(Togg…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check if geemap is working as intended - plot the leaflet map\n",
    "Map = geemap.Map()\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d645ef35",
   "metadata": {
    "id": "d645ef35"
   },
   "source": [
    "## Create Images for Map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d15bd6f",
   "metadata": {},
   "source": [
    "### Load Feature Collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a30bcf7",
   "metadata": {
    "id": "8a30bcf7"
   },
   "outputs": [],
   "source": [
    "#Data loads\n",
    "\n",
    "#loads feature collection data from Google Earth Engine - We can also upload other feature collections\n",
    "counties = ee.FeatureCollection(\"TIGER/2018/Counties\")\n",
    "\n",
    "#filter LA County\n",
    "la_county = counties.filter(ee.Filter.eq('NAME', 'Los Angeles'))\n",
    "sc_county = counties.filter(ee.Filter.eq('NAME', 'Santa Clara'))\n",
    "\n",
    "#loads parcel data\n",
    "la_parcel_shape = ee.FeatureCollection(\"projects/california-lawn-detection/assets/LA_County_Parcels_Shape\")\n",
    "\n",
    "#Income Data\n",
    "la_county_income = ee.FeatureCollection(\"projects/california-lawn-detection/assets/lacountyincome-final\")\n",
    "la_county_income2 = ee.FeatureCollection(\"projects/california-lawn-detection/assets/lacountyincome_update\")\n",
    "la_county_income = la_county_income2.select(ee.List(['Name', 'Descriptio', 'Ranking']), ee.List(['Name', 'Median_Income', 'Ranking']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70838ac",
   "metadata": {
    "id": "b70838ac"
   },
   "source": [
    "### Build Training Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6916f762",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_3bands(image, band):\n",
    "    i_8_bit = image.select(band).toUint8()\n",
    "    square = ee.Kernel.square(**{'radius': 4})\n",
    "    entropy = i_8_bit.entropy(square)\n",
    "    glcm = i_8_bit.glcmTexture(**{'size': 4})\n",
    "    contrast = glcm.select(str(band)+'_contrast')\n",
    "    \n",
    "    # Create a list of weights for a 9x9 kernel.\n",
    "    list = [1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
    "    # The center of the kernel is zero.\n",
    "    centerList = [1, 1, 1, 1, 0, 1, 1, 1, 1]\n",
    "    # Assemble a list of lists: the 9x9 kernel weights as a 2-D matrix.\n",
    "    lists = [list, list, list, list, centerList, list, list, list, list]\n",
    "    # Create the kernel from the weights.\n",
    "    # Non-zero weights represent the spatial neighborhood.\n",
    "    kernel = ee.Kernel.fixed(9, 9, lists, -4, -4, False)\n",
    "    neighs = i_8_bit.neighborhoodToBands(kernel)\n",
    "    gearys = i_8_bit.subtract(neighs).pow(2).reduce(ee.Reducer.sum()).divide(math.pow(9, 2))\n",
    "    image = image.addBands(entropy.rename(str(band)+'_Entropy')).addBands(contrast.rename(str(band)+'_Contrast')).addBands(gearys.rename(str(band)+'_Gearys'))   \n",
    "    return image\n",
    "\n",
    "def add_neighborhood_bands(image):\n",
    "    bands = ['R', 'G', 'B', 'N']\n",
    "    for band in bands:\n",
    "        image = apply_3bands(image, band)\n",
    "    return image\n",
    "    \n",
    "def add_NDVI(image):\n",
    "    image = image.addBands(image.normalizedDifference(['N','R']).rename('NDVI'))\n",
    "    return image\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a48f0f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_images(param_dict):\n",
    "    source_image_collection = param_dict['source_image_collection']\n",
    "    years = param_dict['years']\n",
    "    counties = param_dict['counties']\n",
    "\n",
    "    image_names = []\n",
    "    images = []\n",
    "\n",
    "    combos = list(itertools.product(years, counties.keys()))\n",
    "    for i in combos:\n",
    "        year = str(i[0])\n",
    "        county = i[1]\n",
    "\n",
    "        image_name = str(i[0])+'_'+i[1]\n",
    "        image_names.append(image_name)\n",
    "\n",
    "        image = ee.ImageCollection(source_image_collection)\\\n",
    "                                .filterDate(f'{year}-01-01', f'{year}-12-31')\\\n",
    "                                .select(['R','G','B','N'])\\\n",
    "                                .median().clip(counties[county])\n",
    "        images.append(image)\n",
    "        images_with_3band = list(map(add_neighborhood_bands, images))\n",
    "        images_with_NDVI = list(map(add_NDVI, images_with_3band))\n",
    "    return dict(zip(image_names, images_with_NDVI))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f44d4152",
   "metadata": {
    "id": "f44d4152"
   },
   "outputs": [],
   "source": [
    "training_image_params = {\n",
    "        'source_image_collection' : 'USDA/NAIP/DOQQ',\n",
    "        'years' : [2020],\n",
    "        'counties': {'la_county': la_county}\n",
    "         }\n",
    "\n",
    "TRAINING_IMAGE = get_images(training_image_params)['2020_la_county']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e9b5fe9",
   "metadata": {
    "id": "4e9b5fe9"
   },
   "outputs": [],
   "source": [
    "Map.addLayer(TRAINING_IMAGE, {}, 'TRAINING_IMAGE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "pk6GGp33chIM",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17,
     "referenced_widgets": [
      "57521180d256424c974c1184813bf5f4"
     ]
    },
    "id": "pk6GGp33chIM",
    "outputId": "4a9a7785-eacc-4095-862e-70a1a76e8c7f",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7b4cad3f7e9422c92fde266f68d0536",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(bottom=754.0, center=[20, 0], controls=(WidgetControl(options=['position', 'transparent_bg'], widget=HBox(…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oK8aqN7U5u7A",
   "metadata": {
    "id": "oK8aqN7U5u7A"
   },
   "source": [
    "## Read in CSV data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "76bd6a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(file, classes=None):\n",
    "    \n",
    "    '''\n",
    "    Read data and reshape for CNN input\n",
    "    '''\n",
    "        \n",
    "    # Read in data and shuffle\n",
    "    data = pd.read_csv(file).to_numpy()\n",
    "    np.random.shuffle(data)\n",
    "\n",
    "    # Split into X and Y\n",
    "    X, Y = data[:,:-1], data[:, -1].astype(int)\n",
    "    \n",
    "    # Print class counts if labels are specified\n",
    "    if classes:\n",
    "        _, counts = np.unique(Y, return_counts=True)\n",
    "        print(file)\n",
    "        print(pd.DataFrame({'class': classes, 'counts': counts}))\n",
    "        print()\n",
    "\n",
    "    # Convert Y to sparse dataset\n",
    "    sparse_Y = np.zeros((Y.size, Y.max()+1))\n",
    "    sparse_Y[np.arange(Y.size), Y] = 1\n",
    "\n",
    "    # Reshape for 1x1 kernel convolutions\n",
    "    conv_X = X.reshape((X.shape[0], 1, 1, X.shape[1]))\n",
    "    conv_sparse_Y = sparse_Y.reshape((sparse_Y.shape[0], 1, 1, sparse_Y.shape[1]))\n",
    "        \n",
    "    return conv_X, conv_sparse_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "37041c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File names for the training and testing datasets\n",
    "IMAGES_DIR = '../datasets/GoogleEarth'\n",
    "TRAIN_FILE_PREFIX = 'training_allbands_expanded_0709'\n",
    "TEST_FILE_PREFIX = 'testing_allbands_expanded_0709' \n",
    "\n",
    "FILE_EXT = '.csv'\n",
    "CSV_TRAIN_FILE_PATH = os.path.join(IMAGES_DIR, (TRAIN_FILE_PREFIX + FILE_EXT))\n",
    "CSV_TEST_FILE_PATH = os.path.join(IMAGES_DIR, (TEST_FILE_PREFIX + FILE_EXT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6c3cbdb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../datasets/GoogleEarth/training_allbands_expanded_0709.csv\n",
      "              class  counts\n",
      "0             water    2336\n",
      "1  vegetation_trees   68413\n",
      "2  vegetation_grass  191787\n",
      "3              turf    3290\n",
      "4        impervious  233446\n",
      "5              soil    8995\n",
      "\n",
      "../datasets/GoogleEarth/testing_allbands_expanded_0709.csv\n",
      "              class  counts\n",
      "0             water     275\n",
      "1  vegetation_trees    2801\n",
      "2  vegetation_grass    1532\n",
      "3              turf     860\n",
      "4        impervious    1103\n",
      "5              soil    9003\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Set the seed for data shuffle\n",
    "np.random.seed(123)\n",
    "\n",
    "conv_train_X, conv_sparse_train_Y = read_data(CSV_TRAIN_FILE_PATH, CLASSES)\n",
    "conv_test_X, conv_sparse_test_Y = read_data(CSV_TEST_FILE_PATH, CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4e453aad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((508267, 1, 1, 17), (508267, 1, 1, 6))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_train_X.shape, conv_sparse_train_Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8a0809ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((15574, 1, 1, 17), (15574, 1, 1, 6))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_test_X.shape, conv_sparse_test_Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "xyfj7hQjEY1l",
   "metadata": {
    "id": "xyfj7hQjEY1l"
   },
   "source": [
    "## Build NN models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gvgfCt4QiuPr",
   "metadata": {
    "id": "gvgfCt4QiuPr"
   },
   "source": [
    "### Custom F1 Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "xKOVZ5AYA-JW",
   "metadata": {
    "id": "xKOVZ5AYA-JW"
   },
   "outputs": [],
   "source": [
    "class MultiClassFBeta(keras.metrics.Metric):\n",
    "    '''\n",
    "    Define a custom F-beta metric class to optimize against\n",
    "    during hyperparameter tuning. Class can perform F-beta calcutions\n",
    "    for macro, weighted, and raw scores for any value of beta.\n",
    "    \n",
    "    Default is macro F1 score.\n",
    "    '''\n",
    "    \n",
    "    def __init__(self,  n_class=N_CLASSES, name=None, beta=1, average='macro',\n",
    "                 epsilon=1e-7, **kwargs):\n",
    "        \n",
    "        # If name is not provided, set default name\n",
    "        if not name:\n",
    "            name = f\"{average}_f{beta}\"\n",
    "        print(name)\n",
    "\n",
    "        # initializing an object of the Metric super class\n",
    "        super(MultiClassFBeta, self).__init__(name=name, **kwargs)\n",
    "\n",
    "        # initializing static variables \n",
    "        self.beta_squared = beta**2\n",
    "        self.n_class = n_class\n",
    "        self.average = average\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "        # initializing state variables\n",
    "        self.tp = self.add_weight(name='tp', \n",
    "                                  shape=(self.n_class,), \n",
    "                                  initializer='zeros')     # initializing true positives\n",
    "        self.actual_positives = self.add_weight(name='ap', \n",
    "                                                shape=(self.n_class,), \n",
    "                                                initializer='zeros') # initializing actual positives\n",
    "        self.predicted_positives = self.add_weight(name='pp',\n",
    "                                                   shape=(self.n_class,), \n",
    "                                                   initializer='zeros') # initializing predicted positives\n",
    "\n",
    "    \n",
    "    def update_state(self, ytrue, ypred, sample_weight=None):\n",
    "\n",
    "        '''\n",
    "        Updates the metrics to preserve the running state\n",
    "        '''\n",
    "\n",
    "        # casting ytrue and ypred as float dtype\n",
    "        ytrue = tf.cast(ytrue, tf.float32)\n",
    "        ypred = tf.cast(ypred, tf.float32)\n",
    "\n",
    "        # finding the maximum probability in ypred\n",
    "        max_prob = tf.reduce_max(ypred, axis=-1, keepdims=True)\n",
    "\n",
    "        # making ypred one hot encoded such that the class with the maximum probability \n",
    "        # as encoded as 1 while others as 0\n",
    "        ypred = tf.cast(tf.equal(ypred, max_prob), tf.float32)\n",
    "\n",
    "        # Calculate TP, PP, AP\n",
    "        TP = tf.reshape(tf.reduce_sum(ytrue*ypred, axis=0), [self.n_class])\n",
    "        PP = tf.reshape(tf.reduce_sum(ypred, axis=0), [self.n_class])\n",
    "        AP = tf.reshape(tf.reduce_sum(ytrue, axis=0), [self.n_class])\n",
    "\n",
    "        self.tp.assign_add(TP) # updating true positives atrribute\n",
    "        self.predicted_positives.assign_add(PP) # updating predicted positives atrribute\n",
    "        self.actual_positives.assign_add(AP) # updating actual positives atrribute\n",
    "\n",
    "    def result(self):\n",
    "    \n",
    "        '''\n",
    "        Performs final metric computations and returns result\n",
    "        '''\n",
    "\n",
    "        self.precision = self.tp/(self.predicted_positives+self.epsilon) # calculates precision\n",
    "        self.recall = self.tp/(self.actual_positives+self.epsilon) # calculates recall\n",
    "\n",
    "        # calculating fbeta score\n",
    "        self.fb = (1+self.beta_squared)*self.precision*self.recall / (self.beta_squared*self.precision + self.recall + self.epsilon)\n",
    "\n",
    "        if self.average == 'weighted':\n",
    "            return tf.reduce_sum(self.fb*self.actual_positives / tf.reduce_sum(self.actual_positives))\n",
    "\n",
    "        elif self.average == 'raw':\n",
    "            return self.fb\n",
    "\n",
    "        return tf.reduce_mean(self.fb)\n",
    "\n",
    "    def reset_state(self):\n",
    "        \n",
    "        '''\n",
    "        Reset the tracked metrics (state)\n",
    "        '''\n",
    "\n",
    "        self.tp.assign(tf.zeros(self.n_class)) # resets true positives to zero\n",
    "        self.predicted_positives.assign(tf.zeros(self.n_class)) # resets predicted positives to zero\n",
    "        self.actual_positives.assign(tf.zeros(self.n_class)) # resets actual positives to zero"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "SQyrBi3n-0P6",
   "metadata": {
    "id": "SQyrBi3n-0P6"
   },
   "source": [
    "### KerasTuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1bf860c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNHyperModel(keras_tuner.HyperModel):\n",
    "\n",
    "    \"\"\"\n",
    "    Custom CNN hyperparamater tuning model. \n",
    "    Inherits from keras_tuner HyperModel.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, n_features, n_classes):\n",
    "        \n",
    "        super(CNNHyperModel, self).__init__()\n",
    "        \n",
    "        self.n_features = n_features\n",
    "        self.n_classes = n_classes\n",
    "        \n",
    "\n",
    "    def build(self, hp):\n",
    "        \n",
    "        '''\n",
    "        Build the model with a range of hyperparameters for tuning.\n",
    "        Current hyperparameters being tuned:\n",
    "          - Activation functions\n",
    "          - Learning rate\n",
    "          - # hidden layers\n",
    "          - Nodes (filters) per layer\n",
    "          - Dropout per layer\n",
    "          - Batch size\n",
    "        '''\n",
    "        \n",
    "        # Define ranges for activations, learning rate, and # hidden layers \n",
    "        activation = hp.Choice(\"activation\", [\"relu\", \"tanh\"])\n",
    "        lr = hp.Choice(\"lr\", [1e-4, 3e-4, 6e-4, 1e-3, 3e-3, 6e-3, 1e-2])\n",
    "        hidden_layers = hp.Int(\"layers\", min_value=1, max_value=3)\n",
    "        \n",
    "        \n",
    "        # Set model input shape\n",
    "        model = keras.Sequential()\n",
    "        model.add(layers.Input((None, None, self.n_features,)))\n",
    "        \n",
    "        # For each hiden layer, set the number of nodes/filters and dropout\n",
    "        for i in range(hidden_layers):\n",
    "            \n",
    "            nodes = hp.Int(f\"nodes_{i+1}\", min_value=8, max_value=64, step=8)\n",
    "            model.add(layers.Conv2D(nodes, (1,1), activation=activation))\n",
    "        \n",
    "            dropout_rate = hp.Float(f\"dropout_rate_{i+1}\", min_value=0.0, max_value=0.5, step=0.05)\n",
    "            model.add(layers.Dropout(dropout_rate))\n",
    " \n",
    "        # Add the final output layer\n",
    "        model.add(layers.Conv2D(self.n_classes, (1,1), activation=tf.nn.softmax))\n",
    "        \n",
    "        # Compile the model with the specified loss function, metrics, and learning rate\n",
    "        model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr),\n",
    "                      loss='categorical_crossentropy',\n",
    "                      metrics=[MultiClassFBeta(n_class=self.n_classes), 'accuracy'])\n",
    "        \n",
    "        # Print model architecture\n",
    "        print(model.summary())\n",
    "        \n",
    "        return model\n",
    "\n",
    "    def fit(self, hp, model, *args, **kwargs):\n",
    "        \n",
    "        '''\n",
    "        Fit model on data and tune batch size\n",
    "        '''\n",
    "        \n",
    "        return model.fit(\n",
    "            *args,\n",
    "            batch_size=hp.Int(\"batch_size\", min_value=16, max_value=126, step=8),\n",
    "            **kwargs,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131b144d",
   "metadata": {},
   "source": [
    "## Training pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "abc3fe50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_model(train_X, train_Y, test_X, test_Y, obj, tuning_dir=None, project_name='CNN', \n",
    "               epochs=20, patience=3, search_type='Bayesian', \n",
    "               max_trials=10, per_trial=2, bayesian_beta=2, new_search=False):\n",
    "    \n",
    "    '''\n",
    "    Function to perform hyperparameter search.\n",
    "    \n",
    "    Params\n",
    "    ------\n",
    "    train_X : np.array\n",
    "        Train dataset feature matrix\n",
    "    train_Y : np.array\n",
    "        Train dataset labels matrix\n",
    "    test_X : np.array\n",
    "        Test dataset feature matrix\n",
    "    test_Y : np.array\n",
    "        Test dataset labels matrix\n",
    "    obj: str | keras_tuner.Objective\n",
    "        The objective to optimize for\n",
    "    tuning_dir: str\n",
    "        Path to store tuning trials (defaults to 'path/to/current/parent_directory/model_tuning/')\n",
    "    project_name: str\n",
    "        Directory under tuning_dir to store model tuning results (defaults to 'CNN')\n",
    "    epochs: int\n",
    "        Max number of epochs to train (defaults to 20)\n",
    "    patience: int\n",
    "        Patience for EarlyStopping callback (defaults to 3)\n",
    "    search_type: str\n",
    "        Hyperparameter search type, either 'Random' or 'Bayesian' (defaults to 'Bayesian')\n",
    "    max_trials: int\n",
    "        Maximum number of search trials (defaults to 10)\n",
    "    per_trial: int\n",
    "        The number of models that should be built and fit for each trial (defaults to 2)\n",
    "    bayesian_beta: int\n",
    "        The balancing factor of exploration and exploitation. \n",
    "        The larger it is, the more explorative it is. (defaults to 2)\n",
    "    new_search: bool\n",
    "        Whether to overwrite the previous results in the same directory \n",
    "        or resume the previous search. (defaults to False)\n",
    "\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    CNN_tuner: keras_tuner\n",
    "        The fitted Keras Tuner that stores the results of the \n",
    "        hyperparameter tuning and the associated models.\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    # Get input and output shapes for the CNN model\n",
    "    n_features = train_X.shape[-1]\n",
    "    n_classes = train_Y.shape[-1]\n",
    "    \n",
    "    # Specify the default tuning directory\n",
    "    if not tuning_dir:\n",
    "        tuning_dir = os.path.join(os.path.dirname(os.getcwd()), \"model_tuning\")\n",
    "        tuning_dir\n",
    "\n",
    "    # Use GPU \n",
    "    with tf.device('/device:GPU:0'):\n",
    "        \n",
    "        model = CNNHyperModel(n_features=n_features, n_classes=n_classes)\n",
    "        \n",
    "        # Random search\n",
    "        if search_type=='Random':\n",
    "            CNN_tuner = keras_tuner.RandomSearch(\n",
    "                hypermodel=model,\n",
    "                objective=keras_tuner.Objective(\"val_macro_f1\", direction=\"max\"),\n",
    "                max_trials=max_trials,\n",
    "                executions_per_trial=per_trial,\n",
    "                overwrite=new_search,\n",
    "                directory=tuning_dir,\n",
    "                project_name=project_name,\n",
    "            )\n",
    "        \n",
    "        \n",
    "        # BayesianSearch\n",
    "        elif search_type=='Bayesian':\n",
    "                CNN_tuner = keras_tuner.BayesianOptimization(\n",
    "                hypermodel=model,\n",
    "                objective=keras_tuner.Objective(\"val_macro_f1\", direction=\"max\"),\n",
    "                max_trials=max_trials,\n",
    "                beta=bayesian_beta,\n",
    "                executions_per_trial=per_trial,\n",
    "                overwrite=new_search,\n",
    "                directory=tuning_dir,\n",
    "                project_name=project_name,\n",
    "            )\n",
    "        \n",
    "        # If neither search type is specified, raise an error\n",
    "        else:\n",
    "            raise ValueError(\"search_type must be either 'Random' or 'Bayesian'\")\n",
    "            \n",
    "        # Fit the hyperparameter tuner\n",
    "        CNN_tuner.search(x=train_X, y=train_Y, \n",
    "                         verbose=2, validation_data=(test_X, test_Y), \n",
    "                         epochs=epochs, callbacks=[keras.callbacks.EarlyStopping('val_macro_f1', \n",
    "                                                                             patience=patience, \n",
    "                                                                             mode='max', \n",
    "                                                                             restore_best_weights=True)]\n",
    "                        )\n",
    "        \n",
    "    return CNN_tuner\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c06fde5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_best_models(tuner, model_names, n_models=1, model_dir=None):\n",
    "    \n",
    "    '''\n",
    "    Save the best N models to a directory and return the save path\n",
    "    '''\n",
    "    \n",
    "    # Get the best N models\n",
    "    best_models = tuner.get_best_models()[:n_models]\n",
    "\n",
    "    # Default model directory\n",
    "    if not model_dir:\n",
    "        model_dir = os.path.join(os.path.dirname(os.getcwd()), \"models\")\n",
    "        \n",
    "    if isinstance(model_names, str):\n",
    "        model_names = list(model_names)\n",
    "    \n",
    "    # Save the best N models\n",
    "    for model, model_name in zip(best_models, model_names):\n",
    "        save_dir = os.path.join(model_dir, model_name)\n",
    "        model.save(save_dir)\n",
    "        \n",
    "    return save_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aBgw5K1_CmvK",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 748
    },
    "id": "aBgw5K1_CmvK",
    "outputId": "59b5f109-798d-47e9-b11d-7d6112c85a98",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Search: Running Trial #17\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "tanh              |relu              |activation\n",
      "0.0001            |0.0006            |lr\n",
      "1                 |1                 |layers\n",
      "64                |64                |nodes_1\n",
      "0.5               |0                 |dropout_rate_1\n",
      "120               |120               |batch_size\n",
      "64                |64                |nodes_2\n",
      "0.5               |0                 |dropout_rate_2\n",
      "\n",
      "macro_f1\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, None, None, 64)    1152      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, None, None, 64)    0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, None, None, 6)     390       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,542\n",
      "Trainable params: 1,542\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "4236/4236 - 10s - loss: 0.7923 - macro_f1: 0.3595 - accuracy: 0.7416 - val_loss: 2.5326 - val_macro_f1: 0.2087 - val_accuracy: 0.2287 - 10s/epoch - 2ms/step\n",
      "Epoch 2/30\n"
     ]
    }
   ],
   "source": [
    "# Define hyperparameter tuning params\n",
    "results_dir = 'just_a_test' \n",
    "epochs=30\n",
    "max_trials=20\n",
    "new_search=False\n",
    "per_trial=1\n",
    "objective = keras_tuner.Objective(\"val_macro_f1\", direction=\"max\")\n",
    "\n",
    "# Start hyperparameter search\n",
    "CNN_tuner = tune_model(conv_train_X, conv_sparse_train_Y, conv_test_X, conv_sparse_test_Y,\n",
    "                       objective, project_name=results_dir, epochs=epochs, \n",
    "                       max_trials=max_trials, per_trial=per_trial, new_search=new_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "39L_mkUYavGL",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "39L_mkUYavGL",
    "outputId": "ac07a45b-fd6d-4017-c8a5-61496b3b1c4c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, None, None, 64)    1152      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, None, None, 64)    0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, None, None, 6)     390       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,542\n",
      "Trainable params: 1,542\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-12 03:19:57.028717: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/ec2-user/mids-w210-capstone/models/CNN_allbands_model_1657595997/assets\n"
     ]
    }
   ],
   "source": [
    "# Save the best performing model\n",
    "model_name = f'just_a_test_model_{time():.0f}'\n",
    "save_dir = save_best_models(CNN_tuner, model_name)\n",
    "\n",
    "print(f\"Best N models saved at: {save_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ROZop73w3P2y",
   "metadata": {
    "id": "ROZop73w3P2y"
   },
   "outputs": [],
   "source": [
    "# save_dir = '/home/ec2-user/mids-w210-capstone/models/CNN_Nbands_model_1657535394'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "Av-IEflWbB4s",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Av-IEflWbB4s",
    "outputId": "46a7e2fe-965e-43f4-9926-a6538d6a301f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.iter\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.decay\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.learning_rate\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 0.4294 - macro_f1: 0.8332 - accuracy: 0.8528\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.42944878339767456, 0.8332240581512451, 0.8527674078941345]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load and evaluate model to test it's the same performance\n",
    "\n",
    "best_nn_model = tf.keras.models.load_model(save_dir, custom_objects={'MultiClassFBeta': MultiClassFBeta})\n",
    "best_nn_model.evaluate(conv_test_X, conv_sparse_test_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "C1NdzIoK3I2R",
   "metadata": {
    "id": "C1NdzIoK3I2R"
   },
   "source": [
    "## Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "65b8141c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classification_report(model, X, y_true, class_names, save_dir=None):\n",
    "    \n",
    "    # Get model predictions\n",
    "    y_probs = model.predict(X)\n",
    "    y_preds = y_probs.argmax(axis=-1)\n",
    "\n",
    "    # If conv output, convert to 1d array\n",
    "    if len(y_preds.shape) > 2:\n",
    "        y_preds = y_preds.reshape(-1, 1)\n",
    "        \n",
    "    # If conv input, convert Y to 1d array\n",
    "    if len(y_true.shape) > 2:\n",
    "        n_classes = y_true.shape[-1]\n",
    "        y_true = np.argmax(y_true.reshape(-1, n_classes), axis=1)\n",
    "    \n",
    "    # Get the classification report\n",
    "    report = classification_report(test_Y, y_preds, target_names=class_names)\n",
    "    \n",
    "    # Save the report if directory specified\n",
    "    if save_dir:\n",
    "        save_report = classification_report(test_Y, y_preds, target_names=class_names, \n",
    "                                            output_dict=True)\n",
    "        df = pd.DataFrame(save_report).transpose()\n",
    "        df.to_csv(save_dir)\n",
    "    \n",
    "    return report, y_true, y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fe3f9420",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cmap(R, G, B, increasing_gradient=True, color_scale=256, mult=1):\n",
    "    \n",
    "    # Initialize colormap array\n",
    "    color_vals = np.ones((color_scale, 4))\n",
    "    \n",
    "    # Calculate pixel value range for R,G,B\n",
    "    R_start, R_end = R+(1-R)*(1-mult), R+(1-R)*(mult)\n",
    "    G_start, G_end = G+(1-G)*(1-mult), G+(1-G)*(mult)\n",
    "    B_start, B_end = B+(1-B)*(1-mult), B+(1-B)*(mult)\n",
    "    \n",
    "    bands = [(R_start, R_end), (G_start, G_end), (B_start, B_end)]\n",
    "\n",
    "    # Create range of pixel values for R,G,B\n",
    "    for i, color in enumerate(bands):   \n",
    "        color_vals[:, i] = np.linspace(*color, color_scale)\n",
    "        if increasing_gradient:\n",
    "            color_vals[:, i] = color_vals[:, i][::-1]\n",
    "    \n",
    "    # Create colormap\n",
    "    cmap = ListedColormap(color_vals)\n",
    "    \n",
    "    return cmap    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "81f7c507",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_preds, save_cm_dir=None, **kwargs):\n",
    "    \n",
    "    # Plot the CM\n",
    "    ConfusionMatrixDisplay.from_predictions(y_true, y_preds, **kwargs)\n",
    "    plt.show()\n",
    "    \n",
    "    # Save the CM if directory specified\n",
    "    if save_cm_dir:\n",
    "        plt.savefig(save_cm_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "PbPyKQvT4enq",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PbPyKQvT4enq",
    "outputId": "f74a6898-43e8-426c-ee41-eafdc77fc52e"
   },
   "outputs": [],
   "source": [
    "# Get the classification report and save it\n",
    "report_path = os.path.join(save_dir, 'classification_report.csv')\n",
    "report, y_true, y_preds = get_classification_report(best_nn_model, conv_test_X, conv_sparse_test_Y,\n",
    "                                                   CLASSES, save_dir=report_path)\n",
    "\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "jFCUAO8j6Eke",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 945
    },
    "id": "jFCUAO8j6Eke",
    "outputId": "73a28c0e-88b5-4353-b580-fb97166eff33"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'create_cmap' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [32]\u001b[0m, in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m brown_G \u001b[38;5;241m=\u001b[39m brown_B \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m40\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m256\u001b[39m\n\u001b[1;32m     11\u001b[0m mult \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.75\u001b[39m\n\u001b[0;32m---> 13\u001b[0m brown_cmp \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_cmap\u001b[49m(brown_R, brown_G, brown_B, mult\u001b[38;5;241m=\u001b[39mmult)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Plot the confusion matrix and save the figure\u001b[39;00m\n\u001b[1;32m     16\u001b[0m cm_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(save_dir, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconfusion_matrix.png\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'create_cmap' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA70AAAOUCAYAAABuflRSAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAqkklEQVR4nO3df9DudV3n8dcbj3ACxLWRnQEKrdXEdEbKWzbdXKU1c7XZmUBT06QmpZlG8LBlrg1LrWVWK2KyNg30w1IoPIqZrpVrK+RorhyMxh+RTICRaHmiiQQOqHz2j+915+3xus993ee673PkzeMxc891zvfX9bmcL7fX83x/1RgjAAAA0NERh3sAAAAAsF1ELwAAAG2JXgAAANoSvQAAALQlegEAAGhL9AIAANCW6AUAAKCthaK3ql5ZVbur6saqGlV188G8WVU9s6o+VFV3VNVts21+y8FsCwAAADZSY4yNF6oaSW5L8tEkj09y+xjj4Zt6o6ozkrwtyV8muTTJg5PsSvLlJCtjjFs3sz0AAADYyKLR+61jjBtnf/54kmM3E71V9cAkNyf5UpLHjDG+MJt+apJrk/zmGOPszQ4eAAAADmSh05tXg3cJT0lyYpLfWA3e2XavS3JVkufOwhgAAAC2zKG6kdUTZq9/Pmfeh5Mcl+TbDtFYAAAAuJ84VNF74uz1M3PmrU476RCNBQAAgPuJHYfofY6evd49Z96+/Zb5KlV1dpKzk+SYY455/CmnnLL1owMAAOCwu/baa/eOMY7fym0equi9c/Z61Jx5O/db5quMMS5JckmSrKysjD179mz96AAAADjsqurTW73NQ3V68+rjiOadwrw6bd6pzwAAAHDQDlX0XjN7feKced+V5PYknzpEYwEAAOB+Ysujt6pOqKpTqmrtNbpXJ/lskhdX1bFrln1ckqcm2T3G+OJWjwUAAID7t4Wu6a2qH07ysNlfj09yZFWdP/v7p8cYb16z+GuSnJXk9EzP4M0Y44tV9bIkVyT5QFVdmukxRecl+XySn13ycwAAAMDXWPRGVj+W5Cn7Tfv52evVSd6cDYwxdlfVXUnOT/LaTHdy/tMkrxhjuJ4XAACALbdQ9I4xnrroBscYP5LkR9aZ9+4k7150WwAAALCMQ3UjKwAAADjkRC8AAABtiV4AAADaEr0AAAC0JXoBAABoS/QCAADQlugFAACgLdELAABAW6IXAACAtkQvAAAAbYleAAAA2hK9AAAAtCV6AQAAaEv0AgAA0JboBQAAoC3RCwAAQFuiFwAAgLZELwAAAG2JXgAAANoSvQAAALQlegEAAGhL9AIAANCW6AUAAKAt0QsAAEBbohcAAIC2RC8AAABtiV4AAADaEr0AAAC0JXoBAABoS/QCAADQlugFAACgLdELAABAW6IXAACAtkQvAAAAbYleAAAA2hK9AAAAtCV6AQAAaEv0AgAA0JboBQAAoC3RCwAAQFuiFwAAgLZELwAAAG2JXgAAANoSvQAAALQlegEAAGhL9AIAANCW6AUAAKAt0QsAAEBbohcAAIC2RC8AAABtiV4AAADaEr0AAAC0JXoBAABoS/QCAADQlugFAACgLdELAABAW6IXAACAtkQvAAAAbYleAAAA2hK9AAAAtCV6AQAAaEv0AgAA0JboBQAAoC3RCwAAQFuiFwAAgLZELwAAAG2JXgAAANoSvQAAALQlegEAAGhL9AIAANCW6AUAAKAt0QsAAEBbohcAAIC2RC8AAABtiV4AAADaEr0AAAC0JXoBAABoS/QCAADQlugFAACgLdELAABAW6IXAACAtkQvAAAAbYleAAAA2hK9AAAAtCV6AQAAaEv0AgAA0JboBQAAoC3RCwAAQFuiFwAAgLZELwAAAG2JXgAAANoSvQAAALQlegEAAGhL9AIAANCW6AUAAKAt0QsAAEBbohcAAIC2RC8AAABtiV4AAADaEr0AAAC0JXoBAABoS/QCAADQlugFAACgLdELAABAW6IXAACAtkQvAAAAbYleAAAA2hK9AAAAtCV6AQAAaEv0AgAA0JboBQAAoC3RCwAAQFuiFwAAgLZELwAAAG2JXgAAANoSvQAAALQlegEAAGhL9AIAANCW6AUAAKAt0QsAAEBbohcAAIC2RC8AAABtiV4AAADaEr0AAAC0JXoBAABoS/QCAADQlugFAACgLdELAABAW6IXAACAtkQvAAAAbYleAAAA2hK9AAAAtCV6AQAAaEv0AgAA0JboBQAAoC3RCwAAQFuiFwAAgLZELwAAAG2JXgAAANoSvQAAALQlegEAAGhL9AIAANCW6AUAAKAt0QsAAEBbohcAAIC2RC8AAABtiV4AAADaEr0AAAC0JXoBAABoS/QCAADQlugFAACgLdELAABAW6IXAACAtkQvAAAAbYleAAAA2hK9AAAAtCV6AQAAaEv0AgAA0JboBQAAoC3RCwAAQFsLRW9VHVFV51XV9VW1r6puqaoLq+qYBdevqvqhqvpQVe2tqn+pqk9U1QVVddxyHwEAAADmW/RI70VJXpfkk0nOSbI7yblJ3lVVi2zjF5JcluSuJP8jycuTfGz25/dWVW1y3AAAALChHRstUFWPyRS6V44xzlwz/aYkb0jyvCSXH2D9HUl2Jfloku8dY9w7m/XrVfWlJC9I8rgk1x3cRwAAAID5FjlK+/wkleT1+02/NMmdSV64wfoPTPINST63JnhX3Tp7vWOBcQAAAMCmbHikN8kTktyb5CNrJ44x9lXVdbP56xpj3FVVf5bkGVX1iiRvT/KlJE9N8hNJ3jLGuGHzQwcAAIADW+RI74lJ9o4x7p4z7zNJHlpVR26wjRckeX+SX0pyQ5KbkvxWpmuFX7T4cAEAAGBxixzpPTrJvOBNkn1rlrnnANu4O8mNmSL5j5OMJGcmOX+2jVevt2JVnZ3k7CQ5+eSTFxguAAAATBY50ntnkqPWmbdzzTJzVdXRST6U5LgxxlljjN8bY/z+GOM5Sa5I8qqqetR6648xLhljrIwxVo4//vgFhgsAAACTRaL31kynMM8L35Mynfp8oKO8z07yyEyPOdrf7tkYvnuBcQAAAMCmLBK918yWO23txKrameTUJHs2WP+k2esD5szbsd8rAAAAbJlFoveKTNfg7tpv+ksyXct72eqEqjqhqk6ZndK86pOz17PmbHt12jULjRYAAAA2YcMjrGOMj1XVG5O8tKquTPKeJI9Ocm6Sq5Ncvmbx12QK2dOTXDWb9u5Mjzt65uzRRW/P9NzfM5I8OcnuMcZHt+TTAAAAwBqLnla8K8nNme6i/Kwke5NcnOSCMca9B1pxjPHlqnpakldmCt1fyXTk+IYkr0jyuoMZOAAAAGykxhiHewwLW1lZGXv2bHQJMQAAAPdFVXXtGGNlK7e5yDW9AAAAcJ8kegEAAGhL9AIAANCW6AUAAKAt0QsAAEBbohcAAIC2RC8AAABtiV4AAADaEr0AAAC0JXoBAABoS/QCAADQlugFAACgLdELAABAW6IXAACAtkQvAAAAbYleAAAA2hK9AAAAtCV6AQAAaEv0AgAA0JboBQAAoC3RCwAAQFuiFwAAgLZELwAAAG2JXgAAANoSvQAAALQlegEAAGhL9AIAANCW6AUAAKAt0QsAAEBbohcAAIC2RC8AAABtiV4AAADaEr0AAAC0JXoBAABoS/QCAADQlugFAACgLdELAABAW6IXAACAtkQvAAAAbYleAAAA2hK9AAAAtCV6AQAAaEv0AgAA0JboBQAAoC3RCwAAQFuiFwAAgLZELwAAAG2JXgAAANoSvQAAALQlegEAAGhL9AIAANCW6AUAAKAt0QsAAEBbohcAAIC2RC8AAABtiV4AAADaEr0AAAC0JXoBAABoS/QCAADQlugFAACgLdELAABAW6IXAACAtkQvAAAAbYleAAAA2hK9AAAAtCV6AQAAaEv0AgAA0JboBQAAoC3RCwAAQFuiFwAAgLZELwAAAG2JXgAAANoSvQAAALQlegEAAGhL9AIAANCW6AUAAKAt0QsAAEBbohcAAIC2RC8AAABtiV4AAADaEr0AAAC0JXoBAABoS/QCAADQlugFAACgLdELAABAW6IXAACAtkQvAAAAbYleAAAA2hK9AAAAtCV6AQAAaEv0AgAA0JboBQAAoC3RCwAAQFuiFwAAgLZELwAAAG2JXgAAANoSvQAAALQlegEAAGhL9AIAANCW6AUAAKAt0QsAAEBbohcAAIC2RC8AAABtiV4AAADaEr0AAAC0JXoBAABoS/QCAADQlugFAACgLdELAABAW6IXAACAtkQvAAAAbYleAAAA2hK9AAAAtCV6AQAAaEv0AgAA0JboBQAAoC3RCwAAQFuiFwAAgLZELwAAAG2JXgAAANoSvQAAALQlegEAAGhL9AIAANCW6AUAAKAt0QsAAEBbohcAAIC2RC8AAABtiV4AAADaEr0AAAC0JXoBAABoS/QCAADQlugFAACgLdELAABAW6IXAACAtkQvAAAAbYleAAAA2hK9AAAAtCV6AQAAaEv0AgAA0JboBQAAoC3RCwAAQFuiFwAAgLZELwAAAG2JXgAAANoSvQAAALQlegEAAGhL9AIAANCW6AUAAKAt0QsAAEBbohcAAIC2RC8AAABtiV4AAADaEr0AAAC0JXoBAABoS/QCAADQlugFAACgLdELAABAW6IXAACAtkQvAAAAbYleAAAA2looeqvqiKo6r6qur6p9VXVLVV1YVccs+kZVtaOqzq2qj1bVHVX1z7M///jBDx8AAADWt2PB5S5Kcm6SdyS5MMmjZ3//jqp62hjj3gOtXFVHJvnDJKcnuSzJr8/e+5FJHnZwQwcAAIAD2zB6q+oxSc5JcuUY48w1029K8oYkz0ty+Qab+e9Jnpbke8cY7z/44QIAAMDiFjm9+flJKsnr95t+aZI7k7zwQCvPToF+WZJ3jjHeX5MHHcRYAQAAYFMWid4nJLk3yUfWThxj7Ety3Wz+gTw5yYOSXFtVv5rk9iS3V9Xnq+oXq2rRU6wBAABgUxYJzhOT7B1j3D1n3meSPKmqjhxj3LPO+o+ave5Kck+Sn07yj0lekOSVSU5KctZmBg0AAACLWCR6j04yL3iTZN+aZdaL3tVTmb8xyWPHGNfP/v7Wqnp/khdV1S+PMT45b+WqOjvJ2Uly8sknLzBcAAAAmCxyevOdSY5aZ97ONcus567Z64fXBO+q3529PmW9lccYl4wxVsYYK8cff/yGgwUAAIBVi0TvrUkeWlXzwvekTKc+r3eUN0n+bvb6uTnzPjt7fcgC4wAAAIBNWSR6r5ktd9raiVW1M8mpSfZssP7qDbC+ac681Wn/sMA4AAAAYFMWid4rkoxMN6Ja6yWZruW9bHVCVZ1QVadU1dGr08YYNyX5YJLTquo71yz7gNk2vpTkvQf7AQAAAGA9G0bvGONjSd6Y5IyqurKqXlxVFyZ5XZKrk1y+ZvHXJPmr7HdUOMk5ma77fV9V/VxVnTNb97QkvzjG+NvlPwoAAAB8tUWfkbsryc2Z7qL8rCR7k1yc5IIxxr0brTzG+IuqelKSX5hta2emOP7RMcabNjtoAAAAWESNMQ73GBa2srIy9uzZ6BJiAAAA7ouq6toxxspWbnORa3oBAADgPkn0AgAA0JboBQAAoC3RCwAAQFuiFwAAgLZELwAAAG2JXgAAANoSvQAAALQlegEAAGhL9AIAANCW6AUAAKAt0QsAAEBbohcAAIC2RC8AAABtiV4AAADaEr0AAAC0JXoBAABoS/QCAADQlugFAACgLdELAABAW6IXAACAtkQvAAAAbYleAAAA2hK9AAAAtCV6AQAAaEv0AgAA0JboBQAAoC3RCwAAQFuiFwAAgLZELwAAAG2JXgAAANoSvQAAALQlegEAAGhL9AIAANCW6AUAAKAt0QsAAEBbohcAAIC2RC8AAABtiV4AAADaEr0AAAC0JXoBAABoS/QCAADQlugFAACgLdELAABAW6IXAACAtkQvAAAAbYleAAAA2hK9AAAAtCV6AQAAaEv0AgAA0JboBQAAoC3RCwAAQFuiFwAAgLZELwAAAG2JXgAAANoSvQAAALQlegEAAGhL9AIAANCW6AUAAKAt0QsAAEBbohcAAIC2RC8AAABtiV4AAADaEr0AAAC0JXoBAABoS/QCAADQlugFAACgLdELAABAW6IXAACAtkQvAAAAbYleAAAA2hK9AAAAtCV6AQAAaEv0AgAA0JboBQAAoC3RCwAAQFuiFwAAgLZELwAAAG2JXgAAANoSvQAAALQlegEAAGhL9AIAANCW6AUAAKAt0QsAAEBbohcAAIC2RC8AAABtiV4AAADaEr0AAAC0JXoBAABoS/QCAADQlugFAACgLdELAABAW6IXAACAtkQvAAAAbYleAAAA2hK9AAAAtCV6AQAAaEv0AgAA0JboBQAAoC3RCwAAQFuiFwAAgLZELwAAAG2JXgAAANoSvQAAALQlegEAAGhL9AIAANCW6AUAAKAt0QsAAEBbohcAAIC2RC8AAABtiV4AAADaEr0AAAC0JXoBAABoS/QCAADQlugFAACgLdELAABAW6IXAACAtkQvAAAAbYleAAAA2hK9AAAAtCV6AQAAaEv0AgAA0JboBQAAoC3RCwAAQFuiFwAAgLZELwAAAG2JXgAAANoSvQAAALQlegEAAGhL9AIAANCW6AUAAKAt0QsAAEBbohcAAIC2RC8AAABtiV4AAADaEr0AAAC0JXoBAABoS/QCAADQlugFAACgLdELAABAW6IXAACAtkQvAAAAbYleAAAA2hK9AAAAtCV6AQAAaEv0AgAA0JboBQAAoC3RCwAAQFuiFwAAgLZELwAAAG2JXgAAANoSvQAAALQlegEAAGhL9AIAANCW6AUAAKAt0QsAAEBbohcAAIC2RC8AAABtiV4AAADaEr0AAAC0tVD0VtURVXVeVV1fVfuq6paqurCqjjmYN62qt1bVqKqPH8z6AAAAsIhFj/RelOR1ST6Z5Jwku5Ocm+RdVbWpo8VV9f1Jzkxy12bWAwAAgM3asdECVfWYTKF75RjjzDXTb0ryhiTPS3L5Im9WVccm+bUkb0zyXw5mwAAAALCoRY7SPj9JJXn9ftMvTXJnkhdu4v1enSm0z9/EOgAAAHBQNjzSm+QJSe5N8pG1E8cY+6rqutn8DVXVaUlemuT5Y4zbq2qTQwUAAIDNWeRI74lJ9o4x7p4z7zNJHlpVRx5oA1W1I9OR4feOMd66+WECAADA5i1ypPfoJPOCN0n2rVnmngNs4+VJHpnkBxYf2qSqzk5ydpKcfPLJm10dAACA+7FFjvTemeSodebtXLPMXFX1iCQXJHn1GOPGzQ0vGWNcMsZYGWOsHH/88ZtdHQAAgPuxRY703prk26vqqDmnOJ+U6dTnAx3lvTDJbUneMQvgte995GzaHWOMz25m4AAAALCRRY70XjNb7rS1E6tqZ5JTk+zZYP2HZbou+BNJbljzc1KmU55vyHS9LwAAAGypRY70XpHkZ5LsSvKBNdNfkula3stWJ1TVCUkenORvxxirpzz/VJJ/M2e7v5bpmuD/msRRXgAAALbchtE7xvhYVb0xyUur6sok70ny6CTnJrk6yeVrFn9NkrOSnJ7kqtn675u33ap6bZIvjDHetswHAAAAgPUscqQ3mY7y3pzpLsrPSrI3ycVJLhhj3LstIwMAAIAl1RjjcI9hYSsrK2PPno0uIQYAAOC+qKquHWOsbOU2F7mRFQAAANwniV4AAADaEr0AAAC0JXoBAABoS/QCAADQlugFAACgLdELAABAW6IXAACAtkQvAAAAbYleAAAA2hK9AAAAtCV6AQAAaEv0AgAA0JboBQAAoC3RCwAAQFuiFwAAgLZELwAAAG2JXgAAANoSvQAAALQlegEAAGhL9AIAANCW6AUAAKAt0QsAAEBbohcAAIC2RC8AAABtiV4AAADaEr0AAAC0JXoBAABoS/QCAADQlugFAACgLdELAABAW6IXAACAtkQvAAAAbYleAAAA2hK9AAAAtCV6AQAAaEv0AgAA0JboBQAAoC3RCwAAQFuiFwAAgLZELwAAAG2JXgAAANoSvQAAALQlegEAAGhL9AIAANCW6AUAAKAt0QsAAEBbohcAAIC2RC8AAABtiV4AAADaEr0AAAC0JXoBAABoS/QCAADQlugFAACgLdELAABAW6IXAACAtkQvAAAAbYleAAAA2hK9AAAAtCV6AQAAaEv0AgAA0JboBQAAoC3RCwAAQFuiFwAAgLZELwAAAG2JXgAAANoSvQAAALQlegEAAGhL9AIAANCW6AUAAKAt0QsAAEBbohcAAIC2RC8AAABtiV4AAADaEr0AAAC0JXoBAABoS/QCAADQlugFAACgLdELAABAW6IXAACAtkQvAAAAbYleAAAA2hK9AAAAtCV6AQAAaEv0AgAA0JboBQAAoC3RCwAAQFuiFwAAgLZELwAAAG2JXgAAANoSvQAAALQlegEAAGhL9AIAANCW6AUAAKAt0QsAAEBbohcAAIC2RC8AAABtiV4AAADaEr0AAAC0JXoBAABoS/QCAADQlugFAACgLdELAABAW6IXAACAtkQvAAAAbYleAAAA2hK9AAAAtCV6AQAAaEv0AgAA0JboBQAAoC3RCwAAQFuiFwAAgLZELwAAAG2JXgAAANoSvQAAALQlegEAAGhL9AIAANCW6AUAAKAt0QsAAEBbohcAAIC2RC8AAABtiV4AAADaEr0AAAC0JXoBAABoS/QCAADQlugFAACgLdELAABAW6IXAACAtkQvAAAAbYleAAAA2hK9AAAAtCV6AQAAaEv0AgAA0JboBQAAoC3RCwAAQFuiFwAAgLZELwAAAG2JXgAAANoSvQAAALQlegEAAGhL9AIAANCW6AUAAKAt0QsAAEBbohcAAIC2RC8AAABtiV4AAADaEr0AAAC0JXoBAABoS/QCAADQlugFAACgLdELAABAW6IXAACAtkQvAAAAbYleAAAA2hK9AAAAtCV6AQAAaEv0AgAA0JboBQAAoC3RCwAAQFuiFwAAgLYWit6qOqKqzquq66tqX1XdUlUXVtUxC6z7kKp6WVW9d7beXVX111V1SVV98/IfAQAAAOZb9EjvRUlel+STSc5JsjvJuUneVVUbbePfJ7kwyUjyv5K8NMl7krwwyceq6tsPYtwAAACwoR0bLVBVj8kUuleOMc5cM/2mJG9I8rwklx9gE9cnedQY42/22+7/TvJ/krwqybM3P3QAAAA4sEWO9D4/SSV5/X7TL01yZ6YjtusaY9y8f/DOpr8vyW1JHrvQSAEAAGCTFoneJyS5N8lH1k4cY+xLct1s/qZV1YOTPCjJ3x/M+gAAALCRRaL3xCR7xxh3z5n3mSQPraojD+K9z0/ywCS/cxDrAgAAwIYWid6jk8wL3iTZt2aZhVXVs5P8ZJI/SfLbGyx7dlXtqao9n//85zfzNgAAANzPLRK9dyY5ap15O9css5CqemaSy5Jcm+QHxxjjQMuPMS4ZY6yMMVaOP/74Rd8GAAAAForeWzOdwjwvfE/KdOrzPYu8WVU9I8mVST6R5OljjNsXHikAAABs0iLRe81sudPWTqyqnUlOTbJnkTeqqu9L8o5MjzB62hjjnzY1UgAAANikRaL3iiQjya79pr8k07W8l61OqKoTquqUqvqqa3yr6ulJ/iDJp5L8pzHGbUuMGQAAABayY6MFxhgfq6o3JnlpVV2Z5D1JHp3k3CRXJ7l8zeKvSXJWktOTXJUkVbWS5J2ZnvX720n+c1Xt/x5vWfaDAAAAwP42jN6ZXUluTnJ2kmcl2Zvk4iQXjDHu3WDdx+YrN7y6aJ1lRC8AAABbrja4efLXlZWVlbFnz0KXEAMAAHAfU1XXjjFWtnKbi1zTCwAAAPdJohcAAIC2RC8AAABtiV4AAADaEr0AAAC0JXoBAABoS/QCAADQlugFAACgLdELAABAW6IXAACAtkQvAAAAbYleAAAA2hK9AAAAtCV6AQAAaEv0AgAA0JboBQAAoC3RCwAAQFuiFwAAgLZELwAAAG2JXgAAANoSvQAAALQlegEAAGhL9AIAANCW6AUAAKAt0QsAAEBbohcAAIC2RC8AAABtiV4AAADaEr0AAAC0JXoBAABoS/QCAADQlugFAACgLdELAABAW6IXAACAtkQvAAAAbYleAAAA2hK9AAAAtCV6AQAAaEv0AgAA0JboBQAAoC3RCwAAQFuiFwAAgLZELwAAAG2JXgAAANoSvQAAALQlegEAAGhL9AIAANCW6AUAAKAt0QsAAEBbohcAAIC2RC8AAABtiV4AAADaEr0AAAC0JXoBAABoS/QCAADQlugFAACgLdELAABAW6IXAACAtkQvAAAAbYleAAAA2hK9AAAAtCV6AQAAaEv0AgAA0JboBQAAoC3RCwAAQFuiFwAAgLZELwAAAG2JXgAAANoSvQAAALQlegEAAGhL9AIAANCW6AUAAKAt0QsAAEBbohcAAIC2RC8AAABtiV4AAADaEr0AAAC0JXoBAABoS/QCAADQlugFAACgLdELAABAW6IXAACAtkQvAAAAbYleAAAA2hK9AAAAtCV6AQAAaEv0AgAA0JboBQAAoC3RCwAAQFuiFwAAgLZELwAAAG2JXgAAANoSvQAAALQlegEAAGhL9AIAANCW6AUAAKAt0QsAAEBbohcAAIC2RC8AAABtiV4AAADaEr0AAAC0JXoBAABoS/QCAADQlugFAACgLdELAABAW6IXAACAtkQvAAAAbYleAAAA2hK9AAAAtCV6AQAAaEv0AgAA0JboBQAAoC3RCwAAQFuiFwAAgLZELwAAAG2JXgAAANoSvQAAALQlegEAAGhL9AIAANCW6AUAAKAt0QsAAEBbohcAAIC2RC8AAABtiV4AAADaEr0AAAC0JXoBAABoS/QCAADQlugFAACgLdELAABAW6IXAACAtkQvAAAAbYleAAAA2hK9AAAAtCV6AQAAaEv0AgAA0JboBQAAoC3RCwAAQFuiFwAAgLZELwAAAG2JXgAAANoSvQAAALQlegEAAGhL9AIAANCW6AUAAKAt0QsAAEBbohcAAIC2RC8AAABtiV4AAADaEr0AAAC0JXoBAABoS/QCAADQlugFAACgLdELAABAW6IXAACAtkQvAAAAbYleAAAA2hK9AAAAtCV6AQAAaEv0AgAA0JboBQAAoK2Foreqjqiq86rq+qraV1W3VNWFVXXMom9UVc+sqg9V1R1VdVtV7a6qbzn4oQMAAMCBLXqk96Ikr0vyySTnJNmd5Nwk76qqDbdRVWckeXeSb0jy8iT/M8l/TPLBqjrxIMYNAAAAG9qx0QJV9ZhMoXvlGOPMNdNvSvKGJM9LcvkB1n9gkouT3JLkyWOML8ym/1GSa5P8XJKzD/4jAAAAwHyLHOl9fpJK8vr9pl+a5M4kL9xg/ackOTHJb6wGb5KMMa5LclWS587CGAAAALbUItH7hCT3JvnI2oljjH1JrpvN32j9JPnzOfM+nOS4JN+2wDgAAABgUxaJ3hOT7B1j3D1n3meSPLSqjtxg/dVl562fJCctMA4AAADYlA2v6U1ydJJ5wZsk+9Ysc88B1s8629i33zJfo6rOzleu+b27qj6+/lDhPuOhSfYe7kHAkuzHdGFfpgP7MV08aqs3uEj03pnk364zb+eaZQ60fpIcdTDrjzEuSXJJklTVnjHGygHeC+4T7Mt0YD+mC/syHdiP6aKq9mz1Nhc5vfnWTKcwz4vWkzKd+rzeUd7V9VeXnbd+Mv/UZwAAAFjKItF7zWy509ZOrKqdSU5NslGJXzN7feKced+V5PYkn1pgHAAAALApi0TvFUlGkl37TX9JpmtxL1udUFUnVNUpVbX2Gt2rk3w2yYur6tg1yz4uyVOT7B5jfHHB8V6y4HLw9c6+TAf2Y7qwL9OB/ZgutnxfrjHGxgtVXZzkpUnekeQ9SR6d5NwkH0zyPWOMe2fLvSnJWUlOH2NctWb952SK57/M9Hzf45KclymmHz/GcHozAAAAW26RG1kl01HemzPdRflZme4Md3GSC1aD90DGGLur6q4k5yd5baY7Of9pklcIXgAAALbLQkd6AQAA4L5okWt6t01VHVFV51XV9VW1r6puqaoLq+qYTWzjmVX1oaq6o6puq6rdVfUt2zluWGuZ/biqHlJVL6uq987Wu6uq/rqqLqmqbz4U44dVW/E7eb/tvbWqhuercyht0XeLHVV1blV9dPb94p9nf/7x7Rw7rLXsvlyTH5p9T95bVf9SVZ+oqguq6rjtHj8kSVW9ctZnN86+E9x8kNtZqvkO65HeqvrVTNcGvyPJH2W6VvicJB9I8rSNTp2uqjOSvC1fuVb4wZlOxf5ykpUxxq3rrw1bY5n9uKqekeTdmU73/7+ZLh14bJIfT3JPkieNMT65rR8AZpb9nbzftr4/yTszXc5y4xjjsVs/YvhaW/Dd4sgkf5jk9Ew36/xwpsvBHpnkrjHGz2zf6OErtmBffnWSn8n0/eIPknwx001kn5vk/yV54nDKJ9usqkaS25J8NMnjk9w+xnj4JrexfPONMQ7LT5LHJLk3ydv3m35Ophtc/dAG6z8w0/N9P53k2DXTT539D3DJ4fpsfu4/P1uwHz88yb+bM/1ps/Xfdrg/o5/7x8+y+/J+6xyb5G+TvCHT/SA+frg/n5/7x89W7MdJfj7JlzLdlPOwfyY/98+fLfh+sSPJHUmuTXLEfvPeMtvGqYf7c/rp/5PkW9f8+eNJbt7k+lvSfIfz9ObnJ6kkr99v+qVJ7kzywg3Wf0qSE5P8xhjjC6sTxxjXJbkqyXOr6oFbNFZYz1L78Rjj5jHG38yZ/r5M/yrm6BiHyrK/k9d6daYvXOdvychgcUvtx7PTRl+W5J1jjPfPTg990HYMFDaw7O/kByb5hiSfG197RHj1qNgdS44RNjTGuHHJTWxJ8x3O6H1Cpn/B+sjaiWOMfUmum83faP0k+fM58z6c6bFI37bcEGFDy+7Hc1XVg5M8KMnfLzk+WNSW7MtVdVqmR9ztGmPcvsVjhI0sux8/OdPv3mtnp5benuT2qvp8Vf1iVS361AtY1lL78hjjriR/luQZVfWKqnpEVT28qn4kyU8kecsY44btGDhssS1pvsMZvScm2TvGuHvOvM8keejsupoDrb+67Lz1k+SkJcYHi1h2P17P+Zn+lfZ3lhkcbMLS+/IsCC5N8t4xxlu3YYywkWX340fNXnclOTPJT2e6/vFDSV6Z5De3bqhwQFvx/eIFSd6f5JeS3JDkpiS/leSiJC/awrHCdtqS5juc/2J5dKYbnMyzb80y9xxg/ayzjX37LQPbZdn9+GtU1bOT/GSSP0ny20uNDha3FfvyyzPd7OcHtnBcsBnL7serpzJ/Y5LHjjGun/39rVX1/iQvqqpfHm4wyPbbit/Jdye5MVMY/HGm63jPzPQP6/syXYoCX++2pPkO55HeO5Mctc68nWuWOdD6WWcbi6wPW2HZ/firVNUzM90t9NokPzhmV+rDIbDUvlxVj0hyQZJXb8H1O3Cwlv2dfNfs9cNrgnfV785en3KQY4PNWPZ38tGZzlA4boxx1hjj98YYvz/GeE6SK5K8qqoetd768HVkS5rvcEbvrZlOzZj3AU7KdErHgf716tY1y85bP5l/GBy20rL78b+aPb7oyiSfSPJ010NyiC27L1+Y6eZr75hdO/aIWQjvSHLk7O8nbP2w4assux//3ez1c3PmfXb2+pAlxgeLWnZffnamM292z5m3O1MDfPfSo4TttyXNdzij95rZ+5+2dmJV7cx0C+o9C6yfJE+cM++7Mt184lPLDRE2tOx+vLr892V6Dt/1mZ69909bO0zY0LL78sMyXXfziUzXjq3+nJTpi9cNma73he207H68etOgb5ozb3XaPywxPljUsvvyagw8YM68Hfu9wtezLWm+wxm9V2S6tmDXftNfkum87MtWJ1TVCVV1yuxUjVVXZ/pX1xdX1bFrln1cpgdv7x5jfHF7hg7/atn9OFX19EwPjf9Ukv80xrhtOwcM61h2X/6pJM+Z8/P5JLfM/vya7Ro8zCy1H48xbkrywSSnVdV3rln2AbNtfCnJe7dt9PAVy/5OXr3u/Kw5216dds2ceXDYbGfz1eG8ZLCqLs70aIt3JHlPkkcnOTfT/+F8z+pzxarqTZn+Az19jHHVmvVXr0v4y0xHEI5Lcl6mXxKPH2M4vZltt8x+XFUrST6Q6Vl8/y3J3v23P8Z4y7Z/CMjyv5PX2ebNSb4wxvDMaQ6JLfhu8R2Zfi/fk+QNSf4x0x2c/0OSV40xfvZQfRbu35b8fvGATNf0npZpf357pu8aZ2R6NNfuMcYPHsKPw/1UVf1wprPBkuScJEdmuiQqST49xnjzmmXflG1qvsN9WsOuJDcnOTvJszJ94b84yQVzHqT9NcYYu6vqrkx3oXttprt6/WmSVwheDqFdOfj9+LH5ykX4F62zjOjlUNmVJX4nw9eJXVnuu8VfVNWTkvzCbFs7k/xVkh8dY7xpW0YM8+3KQe7LY4wvV9XTMj1q64wkv5IpEG5I8ookr9u2UcNX+7F87Q0Af372enWSN2cDW9F8h/VILwAAAGynw3lNLwAAAGwr0QsAAEBbohcAAIC2RC8AAABtiV4AAADaEr0AAAC0JXoBAABoS/QCAADQlugFAACgLdELAABAW/8fDqM3oKFtqqAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1152x1152 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rcParams.update({'text.color': \"black\",\n",
    "                     'font.size' : 18,\n",
    "                     })\n",
    "\n",
    "fig = plt.figure(figsize=(16,16))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "# Create brown colormap\n",
    "brown_R = 90/256\n",
    "brown_G = brown_B = 40/256\n",
    "mult = 0.75\n",
    "\n",
    "brown_cmp = create_cmap(brown_R, brown_G, brown_B, mult=mult)\n",
    "\n",
    "# Plot the confusion matrix and save the figure\n",
    "cm_path = os.path.join(save_dir, 'confusion_matrix.png')\n",
    "\n",
    "plot_confusion_matrix(y_true, y_preds, save_cm_dir=cm_path,\n",
    "                      display_labels=CLASSES, ax=ax, normalize='true', \n",
    "                      cmap=brown_cmp, xticks_rotation=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac4067a",
   "metadata": {
    "id": "1ac4067a"
   },
   "source": [
    "## EEificiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "xNBNYHjGUeXG",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xNBNYHjGUeXG",
    "outputId": "e449f510-ca96-4c3e-c3d1-9954e14ae592"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'{\"serving_default_input_1:0\": \"array\"}'\n",
      "'{\"StatefulPartitionedCall:0\": \"output\"}'\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.tools import saved_model_utils\n",
    "\n",
    "meta_graph_def = saved_model_utils.get_meta_graph_def(save_dir, 'serve')\n",
    "inputs = meta_graph_def.signature_def['serving_default'].inputs\n",
    "outputs = meta_graph_def.signature_def['serving_default'].outputs\n",
    "\n",
    "# Just get the first thing(s) from the serving signature def.  i.e. this\n",
    "# model only has a single input and a single output.\n",
    "input_name = None\n",
    "for k,v in inputs.items():\n",
    "  input_name = v.name\n",
    "  break\n",
    "\n",
    "output_name = None\n",
    "for k,v in outputs.items():\n",
    "  output_name = v.name\n",
    "  break\n",
    "\n",
    "# Make a dictionary that maps Earth Engine outputs and inputs to\n",
    "# AI Platform inputs and outputs, respectively.\n",
    "import json\n",
    "input_dict = \"'\" + json.dumps({input_name: \"array\"}) + \"'\"\n",
    "output_dict = \"'\" + json.dumps({output_name: \"output\"}) + \"'\"\n",
    "print(input_dict)\n",
    "print(output_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "lGq7v9tQcwuK",
   "metadata": {
    "id": "lGq7v9tQcwuK"
   },
   "outputs": [],
   "source": [
    "# Put the EEified model in the appropriate bucket and API name\n",
    "PROJECT = 'w210-351617'\n",
    "OUTPUT_BUCKET = 'test-tf-gee'\n",
    "EEIFIED_DIR = 'gs://' + OUTPUT_BUCKET + '/eeified_pixel_model'\n",
    "\n",
    "MODEL_NAME = results_dir\n",
    "VERSION_NAME = 'v0'\n",
    "REGION = 'us-central1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1WNSCgA6Uswh",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1WNSCgA6Uswh",
    "outputId": "92905efd-7461-4963-fe63-5eee87d61ab0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully saved project id\n",
      "Warning: TensorFlow Addons not found. Models that use non-standard ops may not work.\n",
      "Success: model at 'gs://test-tf-gee/eeified_pixel_model' is ready to be hosted in AI Platform.\n"
     ]
    }
   ],
   "source": [
    "# Run the model prepare commands\n",
    "!earthengine set_project {PROJECT}\n",
    "!earthengine model prepare --source_dir {save_dir} --dest_dir {EEIFIED_DIR} --input {input_dict} --output {output_dict}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "68b2a383",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "68b2a383",
    "outputId": "dd1c9583-b4ee-48e7-dbe5-c7886733fe65"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using endpoint [https://us-central1-ml.googleapis.com/]\n",
      "Created ai platform model [projects/w210-351617/models/CNN_allbands_expanded_full].\n",
      "Using endpoint [https://us-central1-ml.googleapis.com/]\n",
      "Creating version (this might take a few minutes)......done.                    \n"
     ]
    }
   ],
   "source": [
    "# Create API endpoint hosted on Google AI Platform\n",
    "!gcloud ai-platform models create {MODEL_NAME} \\\n",
    "  --project {PROJECT} \\\n",
    "  --region {REGION}\n",
    "\n",
    "!gcloud ai-platform versions create {VERSION_NAME} \\\n",
    "  --project {PROJECT} \\\n",
    "  --region {REGION} \\\n",
    "  --model {MODEL_NAME} \\\n",
    "  --origin {EEIFIED_DIR} \\\n",
    "  --framework \"TENSORFLOW\" \\\n",
    "  --runtime-version=2.3 \\\n",
    "  --python-version=3.7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "W7-ZTNO2USY5",
   "metadata": {
    "id": "W7-ZTNO2USY5"
   },
   "source": [
    "## Visualize model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17db9a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_TF_classified_image(image, bands, tf_model, classes):\n",
    "    \n",
    "    '''\n",
    "    Use a TF model hosted on Google AI Platform to classify an EE image.\n",
    "    '''\n",
    "    \n",
    "    # Select bands from training image for classification\n",
    "    selected_image = image.select(bands)\n",
    "\n",
    "    # Get the predictions\n",
    "    predictions = tf_model.predictImage(selected_image.float().toArray())\n",
    "    probabilities = predictions.arrayFlatten([classes])\n",
    "    classified_image = predictions.arrayArgmax().arrayGet([0]).rename('classification')\n",
    "    \n",
    "    return classified_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ecfb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Point to the specific TF model to be used for inference\n",
    "PROJECT = 'w210-351617'\n",
    "MODEL_NAME = 'CNN_Nbands_model'\n",
    "VERSION_NAME = 'v0'\n",
    "input_dim = [12,12]\n",
    "\n",
    "# Point to the model hosted on AI Platform.\n",
    "tf_model = ee.Model.fromAiPlatformPredictor(\n",
    "    projectName=PROJECT,\n",
    "    modelName=MODEL_NAME,\n",
    "    version=VERSION_NAME,\n",
    "    # Can be anything, but don't make it too big.\n",
    "    inputTileSize=input_dim,\n",
    "    # Note the names here need to match what was specified in the\n",
    "    # output dictionary passed to the EEifier originally\n",
    "    outputBands={'output': {\n",
    "        'type': ee.PixelType.float(),\n",
    "        'dimensions': 1\n",
    "      }\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "QLsJqL-5V1cB",
   "metadata": {
    "id": "QLsJqL-5V1cB"
   },
   "outputs": [],
   "source": [
    "# Classify the training image\n",
    "training_image_classified = get_TF_classified_image(TRAINING_IMAGE, BANDS, tf_model, CLASSES)\n",
    "\n",
    "assert(training_image_classified.bandNames().getInfo() == ['classification'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "y3ZIgs3MV2V1",
   "metadata": {
    "id": "y3ZIgs3MV2V1"
   },
   "outputs": [],
   "source": [
    "legend_colors = ['#0B6AEF', '#097407', '#0CE708', '#8C46D2' ,' #A1A8AF','#D47911']\n",
    "\n",
    "Map.addLayer(training_image_classified, {'min': 0, 'max': 5, 'palette': legend_colors}, 'Classification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "WczXRqBZdBkR",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17,
     "referenced_widgets": [
      "4b7582aa96ab4a52835aefa67a9e1b78"
     ]
    },
    "id": "WczXRqBZdBkR",
    "outputId": "576d99c2-1528-4316-ff14-b1fe46d3d218"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1ccffc5652f48e5ab76f0d1d2dfef00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(bottom=3352500.0, center=[33.956745298141946, -118.26524842010575], controls=(WidgetControl(options=['posi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Map"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "data_preprocessing+NN_tuning_ST.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "4b7582aa96ab4a52835aefa67a9e1b78": {
     "model_module": "jupyter-leaflet",
     "model_module_version": "^0.17.0",
     "model_name": "LeafletMapModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "jupyter-leaflet",
      "_model_module_version": "^0.17.0",
      "_model_name": "LeafletMapModel",
      "_view_count": null,
      "_view_module": "jupyter-leaflet",
      "_view_module_version": "^0.17.0",
      "_view_name": "LeafletMapView",
      "bottom": 0,
      "bounce_at_zoom_limits": true,
      "box_zoom": true,
      "center": [
       20,
       0
      ],
      "close_popup_on_click": true,
      "controls": [
       "IPY_MODEL_f407b3b2aabc4a668d073134666ad7eb",
       "IPY_MODEL_e636c61ebe194a288dbad13e7f065b74",
       "IPY_MODEL_a9c7613569174982b5861a86de416c4b",
       "IPY_MODEL_8a49174c73704adfb73fc92e533e2198",
       "IPY_MODEL_e21d1e9d2321493aae367b9264c6bd3a",
       "IPY_MODEL_42a43a59ac5b403389a61a2c6a135ce8",
       "IPY_MODEL_54d651e3bc9f40c091ab118a6d45d6f2",
       "IPY_MODEL_1ec93dd741bf42ca8ccd98e991929c55"
      ],
      "crs": {
       "custom": false,
       "name": "EPSG3857"
      },
      "default_style": "IPY_MODEL_56c76996b3284e6e9f00881f6a6a3a65",
      "double_click_zoom": true,
      "dragging": true,
      "dragging_style": "IPY_MODEL_90834ecc6d834efba53762d767ebc907",
      "east": 0,
      "fullscreen": false,
      "inertia": true,
      "inertia_deceleration": 3000,
      "inertia_max_speed": 1500,
      "interpolation": "bilinear",
      "keyboard": true,
      "keyboard_pan_offset": 80,
      "keyboard_zoom_offset": 1,
      "layers": [
       "IPY_MODEL_406f2816e09d495cb4bcdcb4bbca8061",
       "IPY_MODEL_6fc89369dc8545d3a3eb199031da2b44",
       "IPY_MODEL_e9f56479c5bb402b911e41508823d8be",
       "IPY_MODEL_05d5f9e70da64ee385afc81af124dc8b"
      ],
      "layout": "IPY_MODEL_84dcb6fceafb4dfba5d93b76cd2a2e5a",
      "left": 9007199254740991,
      "max_zoom": 24,
      "min_zoom": null,
      "modisdate": "2022-07-08",
      "north": 0,
      "options": [
       "bounce_at_zoom_limits",
       "box_zoom",
       "center",
       "close_popup_on_click",
       "double_click_zoom",
       "dragging",
       "fullscreen",
       "inertia",
       "inertia_deceleration",
       "inertia_max_speed",
       "interpolation",
       "keyboard",
       "keyboard_pan_offset",
       "keyboard_zoom_offset",
       "max_zoom",
       "min_zoom",
       "prefer_canvas",
       "scroll_wheel_zoom",
       "tap",
       "tap_tolerance",
       "touch_zoom",
       "world_copy_jump",
       "zoom",
       "zoom_animation_threshold",
       "zoom_delta",
       "zoom_snap"
      ],
      "panes": {},
      "prefer_canvas": false,
      "right": 0,
      "scroll_wheel_zoom": true,
      "south": 0,
      "style": "IPY_MODEL_bf93fa7864f24136849e99eb21f36e91",
      "tap": true,
      "tap_tolerance": 15,
      "top": 9007199254740991,
      "touch_zoom": true,
      "west": 0,
      "window_url": "",
      "world_copy_jump": false,
      "zoom": 2,
      "zoom_animation_threshold": 4,
      "zoom_delta": 1,
      "zoom_snap": 1
     }
    },
    "57521180d256424c974c1184813bf5f4": {
     "model_module": "jupyter-leaflet",
     "model_module_version": "^0.17.0",
     "model_name": "LeafletMapModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "jupyter-leaflet",
      "_model_module_version": "^0.17.0",
      "_model_name": "LeafletMapModel",
      "_view_count": null,
      "_view_module": "jupyter-leaflet",
      "_view_module_version": "^0.17.0",
      "_view_name": "LeafletMapView",
      "bottom": 0,
      "bounce_at_zoom_limits": true,
      "box_zoom": true,
      "center": [
       20,
       0
      ],
      "close_popup_on_click": true,
      "controls": [
       "IPY_MODEL_c9c6de26ce2344cdb28d40828c5c0a44",
       "IPY_MODEL_dfecac8bb1404b80bb1193b78ab66d0d",
       "IPY_MODEL_320f6bbbb4fc4639aef5bb255cdb1606",
       "IPY_MODEL_bd9ef45459674181a5cf0ee3bd475dc6",
       "IPY_MODEL_c32e4cd0472645908d4cd8f26d464415",
       "IPY_MODEL_4d8ae2aac44946e68d28407e30a84785",
       "IPY_MODEL_83aef1cb3ffa4ca3958d1ba41e47225e",
       "IPY_MODEL_f8127a6e10c248ed9a19e36f262d7238"
      ],
      "crs": {
       "custom": false,
       "name": "EPSG3857"
      },
      "default_style": "IPY_MODEL_92d3b3aa3fa6489f957889931a5a74fb",
      "double_click_zoom": true,
      "dragging": true,
      "dragging_style": "IPY_MODEL_6941cd9f854f46ebb5918794c8d74f11",
      "east": 0,
      "fullscreen": false,
      "inertia": true,
      "inertia_deceleration": 3000,
      "inertia_max_speed": 1500,
      "interpolation": "bilinear",
      "keyboard": true,
      "keyboard_pan_offset": 80,
      "keyboard_zoom_offset": 1,
      "layers": [
       "IPY_MODEL_e08f1b425dd4434eb2f790e5a786fe6e",
       "IPY_MODEL_75e8619b04ee4debb4178374cca2ab3e",
       "IPY_MODEL_10d9755c15624490be027c05502d769a"
      ],
      "layout": "IPY_MODEL_435ea1de61004d51bdb9e67d43bbe2d0",
      "left": 9007199254740991,
      "max_zoom": 24,
      "min_zoom": null,
      "modisdate": "2022-07-08",
      "north": 0,
      "options": [
       "bounce_at_zoom_limits",
       "box_zoom",
       "center",
       "close_popup_on_click",
       "double_click_zoom",
       "dragging",
       "fullscreen",
       "inertia",
       "inertia_deceleration",
       "inertia_max_speed",
       "interpolation",
       "keyboard",
       "keyboard_pan_offset",
       "keyboard_zoom_offset",
       "max_zoom",
       "min_zoom",
       "prefer_canvas",
       "scroll_wheel_zoom",
       "tap",
       "tap_tolerance",
       "touch_zoom",
       "world_copy_jump",
       "zoom",
       "zoom_animation_threshold",
       "zoom_delta",
       "zoom_snap"
      ],
      "panes": {},
      "prefer_canvas": false,
      "right": 0,
      "scroll_wheel_zoom": true,
      "south": 0,
      "style": "IPY_MODEL_e8c98861804e4a46b5b5525263ed0e60",
      "tap": true,
      "tap_tolerance": 15,
      "top": 9007199254740991,
      "touch_zoom": true,
      "west": 0,
      "window_url": "",
      "world_copy_jump": false,
      "zoom": 2,
      "zoom_animation_threshold": 4,
      "zoom_delta": 1,
      "zoom_snap": 1
     }
    },
    "c9a017e6dd2f474b8e34648f641f72b5": {
     "model_module": "jupyter-leaflet",
     "model_module_version": "^0.17.0",
     "model_name": "LeafletMapModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "jupyter-leaflet",
      "_model_module_version": "^0.17.0",
      "_model_name": "LeafletMapModel",
      "_view_count": null,
      "_view_module": "jupyter-leaflet",
      "_view_module_version": "^0.17.0",
      "_view_name": "LeafletMapView",
      "bottom": 0,
      "bounce_at_zoom_limits": true,
      "box_zoom": true,
      "center": [
       0,
       0
      ],
      "close_popup_on_click": true,
      "controls": [
       "IPY_MODEL_3eaa35cb1a1342f6b7c5fcd203e4c9d8",
       "IPY_MODEL_051655ef7768437a885746163e151519"
      ],
      "crs": {
       "custom": false,
       "name": "EPSG3857"
      },
      "default_style": "IPY_MODEL_843b0e1a73694c1bade8660e90a770a0",
      "double_click_zoom": true,
      "dragging": true,
      "dragging_style": "IPY_MODEL_435ad546d1ad4b1da7cfaf8fd3b7a90c",
      "east": 0,
      "fullscreen": false,
      "inertia": true,
      "inertia_deceleration": 3000,
      "inertia_max_speed": 1500,
      "interpolation": "bilinear",
      "keyboard": true,
      "keyboard_pan_offset": 80,
      "keyboard_zoom_offset": 1,
      "layers": [
       "IPY_MODEL_84550e6cafb64e9b969488fe9239d267"
      ],
      "layout": "IPY_MODEL_b486a4cf9c5248fd92128d7a6d176e06",
      "left": 9007199254740991,
      "max_zoom": null,
      "min_zoom": null,
      "modisdate": "2022-07-08",
      "north": 0,
      "options": [
       "bounce_at_zoom_limits",
       "box_zoom",
       "center",
       "close_popup_on_click",
       "double_click_zoom",
       "dragging",
       "fullscreen",
       "inertia",
       "inertia_deceleration",
       "inertia_max_speed",
       "interpolation",
       "keyboard",
       "keyboard_pan_offset",
       "keyboard_zoom_offset",
       "max_zoom",
       "min_zoom",
       "prefer_canvas",
       "scroll_wheel_zoom",
       "tap",
       "tap_tolerance",
       "touch_zoom",
       "world_copy_jump",
       "zoom",
       "zoom_animation_threshold",
       "zoom_delta",
       "zoom_snap"
      ],
      "panes": {},
      "prefer_canvas": false,
      "right": 0,
      "scroll_wheel_zoom": false,
      "south": 0,
      "style": "IPY_MODEL_1756055d52a24290902d641bc328307f",
      "tap": true,
      "tap_tolerance": 15,
      "top": 9007199254740991,
      "touch_zoom": true,
      "west": 0,
      "window_url": "",
      "world_copy_jump": false,
      "zoom": null,
      "zoom_animation_threshold": 4,
      "zoom_delta": 1,
      "zoom_snap": 1
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
