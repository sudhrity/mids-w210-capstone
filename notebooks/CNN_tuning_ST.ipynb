{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c099915",
   "metadata": {
    "id": "6c099915"
   },
   "source": [
    "# Google Earth Engine Component"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b600c4",
   "metadata": {
    "id": "f1b600c4"
   },
   "source": [
    "## Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "10a33a5d",
   "metadata": {
    "id": "10a33a5d"
   },
   "outputs": [],
   "source": [
    "#Import required libraries\n",
    "import os\n",
    "import json\n",
    "from time import time\n",
    "import math\n",
    "import itertools\n",
    "\n",
    "import ee\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import keras_tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07092838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-19 06:43:59.955869: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-19 06:43:59.963909: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-19 06:43:59.965482: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    }
   ],
   "source": [
    "# Check number of available GPUs\n",
    "n_gpus = len(tf.config.list_physical_devices('GPU'))\n",
    "assert n_gpus >= 1\n",
    "print(\"Num GPUs Available:\", n_gpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2bf9b8c4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2bf9b8c4",
    "outputId": "51de3b2c-7998-45eb-d39b-f0d307b84740",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p>To authorize access needed by Earth Engine, open the following\n",
       "        URL in a web browser and follow the instructions:</p>\n",
       "        <p><a href=https://code.earthengine.google.com/client-auth?scopes=https%3A//www.googleapis.com/auth/earthengine%20https%3A//www.googleapis.com/auth/devstorage.full_control&request_id=EafOdfO1SoafiMB59ODVawEsZNwYsJ7JfGj8TC3MMcE&tc=jDB2u37OdWA6v3Bo9B1ixbQFbiZB95R-jMgBaG7OlhY&cc=gc6M2h84RpzQidp5vHmTADZKxeI049EfOyzgrzwiNTQ>https://code.earthengine.google.com/client-auth?scopes=https%3A//www.googleapis.com/auth/earthengine%20https%3A//www.googleapis.com/auth/devstorage.full_control&request_id=EafOdfO1SoafiMB59ODVawEsZNwYsJ7JfGj8TC3MMcE&tc=jDB2u37OdWA6v3Bo9B1ixbQFbiZB95R-jMgBaG7OlhY&cc=gc6M2h84RpzQidp5vHmTADZKxeI049EfOyzgrzwiNTQ</a></p>\n",
       "        <p>The authorization workflow will generate a code, which you\n",
       "        should paste in the box below</p>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter verification code: 4/1AdQt8qiZ7fvAzT1BU6ac6O4P76j-PRt-GuwQqNtRL1SfAzJDvRXoAs-UO6c\n",
      "\n",
      "Successfully saved authorization token.\n"
     ]
    }
   ],
   "source": [
    "#Initialize Google Earth Engine\n",
    "#just needed the 1st time\n",
    "ee.Authenticate() \n",
    "ee.Initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e5b42a",
   "metadata": {},
   "source": [
    "## Define Globals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b8b282e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17,
     "referenced_widgets": [
      "57521180d256424c974c1184813bf5f4"
     ]
    },
    "id": "0b8b282e",
    "outputId": "aff1cb3c-46b2-4025-f839-2007c003190e"
   },
   "outputs": [],
   "source": [
    "# Define classes\n",
    "CLASSES = ['water',\n",
    "           'vegetation_trees',\n",
    "           'vegetation_grass',\n",
    "           'turf',\n",
    "           'impervious',\n",
    "           'soil']\n",
    "\n",
    "# Change classes to include lakes\n",
    "CLASSES[0] = 'pools'\n",
    "CLASSES_P1 = CLASSES + ['lakes']\n",
    "\n",
    "N_CLASSES = len(CLASSES)\n",
    "\n",
    "# Define the label and bands\n",
    "LABEL = 'landcover'\n",
    "NBANDS = ['R', \n",
    "         'G', \n",
    "         'B', \n",
    "         'N', \n",
    "         'NDVI',\n",
    "         'N_Entropy', \n",
    "         'N_Contrast', \n",
    "         'N_Gearys']\n",
    "\n",
    "ALL_BANDS = NBANDS + ['R_Entropy',\n",
    "                      'R_Contrast',\n",
    "                      'R_Gearys',\n",
    "                      'G_Entropy',\n",
    "                      'G_Contrast',\n",
    "                      'G_Gearys',\n",
    "                      'B_Entropy',\n",
    "                      'B_Contrast',\n",
    "                      'B_Gearys']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da804195",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select desired band set\n",
    "BANDS = NBANDS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oK8aqN7U5u7A",
   "metadata": {
    "id": "oK8aqN7U5u7A"
   },
   "source": [
    "## Read in CSV data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76bd6a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(file, classes=None):\n",
    "    \n",
    "    '''\n",
    "    Read data and reshape for CNN input\n",
    "    '''\n",
    "        \n",
    "    # Read in data and shuffle\n",
    "    data = pd.read_csv(file).to_numpy()\n",
    "    np.random.shuffle(data)\n",
    "\n",
    "    # Split into X and Y\n",
    "    X, Y = data[:,:-1], data[:, -1].astype(int)\n",
    "    \n",
    "    # Print class counts if labels are specified\n",
    "    if classes:\n",
    "        _, counts = np.unique(Y, return_counts=True)\n",
    "        print(file)\n",
    "        df = pd.DataFrame({'class': classes, 'counts': counts})\n",
    "        df['proportion'] = df['counts']/df['counts'].sum()\n",
    "        print(df)\n",
    "        print()\n",
    "\n",
    "    # Convert Y to sparse dataset\n",
    "    sparse_Y = np.zeros((Y.size, Y.max()+1))\n",
    "    sparse_Y[np.arange(Y.size), Y] = 1\n",
    "\n",
    "    # Reshape for 1x1 kernel convolutions\n",
    "    conv_X = X.reshape((X.shape[0], 1, 1, X.shape[1]))\n",
    "    conv_sparse_Y = sparse_Y.reshape((sparse_Y.shape[0], 1, 1, sparse_Y.shape[1]))\n",
    "        \n",
    "    return conv_X, conv_sparse_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37041c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File names for the training and testing datasets\n",
    "IMAGES_DIR = '../datasets/GoogleEarth'\n",
    "TRAIN_FILE_PREFIX = 'training_waterlake_Nbands_0717_v12'\n",
    "TEST_FILE_PREFIX = 'testing_waterlake_Nbands_0717_v12' \n",
    "FILE_EXT = '.csv'\n",
    "\n",
    "CSV_TRAIN_FILE_PATH = os.path.join(IMAGES_DIR, (TRAIN_FILE_PREFIX + FILE_EXT))\n",
    "CSV_TEST_FILE_PATH = os.path.join(IMAGES_DIR, (TEST_FILE_PREFIX + FILE_EXT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c3cbdb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../datasets/GoogleEarth/training_waterlake_Nbands_0717_v12.csv\n",
      "              class  counts  proportion\n",
      "0             pools    4754    0.018918\n",
      "1  vegetation_trees   68413    0.272243\n",
      "2  vegetation_grass   94741    0.377013\n",
      "3              turf    3290    0.013092\n",
      "4        impervious   71101    0.282940\n",
      "5              soil    8995    0.035795\n",
      "\n",
      "../datasets/GoogleEarth/testing_waterlake_Nbands_0717_v12.csv\n",
      "              class  counts  proportion\n",
      "0             pools    1351    0.030826\n",
      "1  vegetation_trees    4770    0.108840\n",
      "2  vegetation_grass    8521    0.194428\n",
      "3              turf    2635    0.060124\n",
      "4        impervious    7006    0.159859\n",
      "5              soil   19543    0.445923\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Set the seed for data shuffle\n",
    "np.random.seed(123)\n",
    "\n",
    "conv_train_X, conv_sparse_train_Y = read_data(CSV_TRAIN_FILE_PATH, CLASSES)\n",
    "conv_test_X, conv_sparse_test_Y = read_data(CSV_TEST_FILE_PATH, CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4e453aad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((251294, 1, 1, 8), (251294, 1, 1, 6))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_train_X.shape, conv_sparse_train_Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a0809ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((43826, 1, 1, 8), (43826, 1, 1, 6))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_test_X.shape, conv_sparse_test_Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "xyfj7hQjEY1l",
   "metadata": {
    "id": "xyfj7hQjEY1l"
   },
   "source": [
    "## Build NN models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gvgfCt4QiuPr",
   "metadata": {
    "id": "gvgfCt4QiuPr"
   },
   "source": [
    "### Custom F1 Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "xKOVZ5AYA-JW",
   "metadata": {
    "id": "xKOVZ5AYA-JW"
   },
   "outputs": [],
   "source": [
    "class MultiClassFBeta(keras.metrics.Metric):\n",
    "    '''\n",
    "    Define a custom F-beta metric class to optimize against\n",
    "    during hyperparameter tuning. Class can perform F-beta calcutions\n",
    "    for macro, weighted, and raw scores for any value of beta.\n",
    "    \n",
    "    Default is macro F1 score.\n",
    "    '''\n",
    "    \n",
    "    def __init__(self,  n_class=N_CLASSES, name=None, beta=1, average='macro',\n",
    "                 epsilon=1e-7, **kwargs):\n",
    "        \n",
    "        # If name is not provided, set default name\n",
    "        if not name:\n",
    "            name = f\"{average}_f{beta}\"\n",
    "        print(name)\n",
    "\n",
    "        # initializing an object of the Metric super class\n",
    "        super(MultiClassFBeta, self).__init__(name=name, **kwargs)\n",
    "\n",
    "        # initializing static variables \n",
    "        self.beta_squared = beta**2\n",
    "        self.n_class = n_class\n",
    "        self.average = average\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "        # initializing state variables\n",
    "        self.tp = self.add_weight(name='tp', \n",
    "                                  shape=(self.n_class,), \n",
    "                                  initializer='zeros')     # initializing true positives\n",
    "        self.actual_positives = self.add_weight(name='ap', \n",
    "                                                shape=(self.n_class,), \n",
    "                                                initializer='zeros') # initializing actual positives\n",
    "        self.predicted_positives = self.add_weight(name='pp',\n",
    "                                                   shape=(self.n_class,), \n",
    "                                                   initializer='zeros') # initializing predicted positives\n",
    "\n",
    "    \n",
    "    def update_state(self, ytrue, ypred, sample_weight=None):\n",
    "\n",
    "        '''\n",
    "        Updates the metrics to preserve the running state\n",
    "        '''\n",
    "\n",
    "        # casting ytrue and ypred as float dtype\n",
    "        ytrue = tf.cast(ytrue, tf.float32)\n",
    "        ypred = tf.cast(ypred, tf.float32)\n",
    "\n",
    "        # finding the maximum probability in ypred\n",
    "        max_prob = tf.reduce_max(ypred, axis=-1, keepdims=True)\n",
    "\n",
    "        # making ypred one hot encoded such that the class with the maximum probability \n",
    "        # as encoded as 1 while others as 0\n",
    "        ypred = tf.cast(tf.equal(ypred, max_prob), tf.float32)\n",
    "\n",
    "        # Calculate TP, PP, AP\n",
    "        TP = tf.reshape(tf.reduce_sum(ytrue*ypred, axis=0), [self.n_class])\n",
    "        PP = tf.reshape(tf.reduce_sum(ypred, axis=0), [self.n_class])\n",
    "        AP = tf.reshape(tf.reduce_sum(ytrue, axis=0), [self.n_class])\n",
    "\n",
    "        self.tp.assign_add(TP) # updating true positives atrribute\n",
    "        self.predicted_positives.assign_add(PP) # updating predicted positives atrribute\n",
    "        self.actual_positives.assign_add(AP) # updating actual positives atrribute\n",
    "\n",
    "    def result(self):\n",
    "    \n",
    "        '''\n",
    "        Performs final metric computations and returns result\n",
    "        '''\n",
    "\n",
    "        self.precision = self.tp/(self.predicted_positives+self.epsilon) # calculates precision\n",
    "        self.recall = self.tp/(self.actual_positives+self.epsilon) # calculates recall\n",
    "\n",
    "        # calculating fbeta score\n",
    "        self.fb = (1+self.beta_squared)*self.precision*self.recall / (self.beta_squared*self.precision + self.recall + self.epsilon)\n",
    "\n",
    "        if self.average == 'weighted':\n",
    "            return tf.reduce_sum(self.fb*self.actual_positives / tf.reduce_sum(self.actual_positives))\n",
    "\n",
    "        elif self.average == 'raw':\n",
    "            return self.fb\n",
    "\n",
    "        return tf.reduce_mean(self.fb)\n",
    "\n",
    "    def reset_state(self):\n",
    "        \n",
    "        '''\n",
    "        Reset the tracked metrics (state)\n",
    "        '''\n",
    "\n",
    "        self.tp.assign(tf.zeros(self.n_class)) # resets true positives to zero\n",
    "        self.predicted_positives.assign(tf.zeros(self.n_class)) # resets predicted positives to zero\n",
    "        self.actual_positives.assign(tf.zeros(self.n_class)) # resets actual positives to zero"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "SQyrBi3n-0P6",
   "metadata": {
    "id": "SQyrBi3n-0P6"
   },
   "source": [
    "### KerasTuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1bf860c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNHyperModel(keras_tuner.HyperModel):\n",
    "\n",
    "    \"\"\"\n",
    "    Custom CNN hyperparamater tuning model. \n",
    "    Inherits from keras_tuner HyperModel.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, n_features, n_classes):\n",
    "        \n",
    "        super(CNNHyperModel, self).__init__()\n",
    "        \n",
    "        self.n_features = n_features\n",
    "        self.n_classes = n_classes\n",
    "        \n",
    "\n",
    "    def build(self, hp):\n",
    "        \n",
    "        '''\n",
    "        Build the model with a range of hyperparameters for tuning.\n",
    "        Current hyperparameters being tuned:\n",
    "          - Activation functions\n",
    "          - Learning rate\n",
    "          - # hidden layers\n",
    "          - Nodes (filters) per layer\n",
    "          - Dropout per layer\n",
    "          - Batch size\n",
    "        '''\n",
    "        \n",
    "        # Define ranges for activations, learning rate, and # hidden layers \n",
    "        activation = hp.Choice(\"activation\", [\"relu\", \"tanh\"])\n",
    "        lr = hp.Choice(\"lr\", [1e-4, 3e-4, 6e-4, 1e-3, 3e-3, 6e-3, 1e-2])\n",
    "        hidden_layers = hp.Int(\"layers\", min_value=1, max_value=3)\n",
    "        \n",
    "        \n",
    "        # Set model input shape\n",
    "        model = keras.Sequential()\n",
    "        model.add(layers.Input((None, None, self.n_features,)))\n",
    "        \n",
    "        # For each hiden layer, set the number of nodes/filters and dropout\n",
    "        for i in range(hidden_layers):\n",
    "            \n",
    "            nodes = hp.Int(f\"nodes_{i+1}\", min_value=8, max_value=64, step=8)\n",
    "            model.add(layers.Conv2D(nodes, (1,1), activation=activation))\n",
    "        \n",
    "            dropout_rate = hp.Float(f\"dropout_rate_{i+1}\", min_value=0.0, max_value=0.5, step=0.05)\n",
    "            model.add(layers.Dropout(dropout_rate))\n",
    " \n",
    "        # Add the final output layer\n",
    "        model.add(layers.Conv2D(self.n_classes, (1,1), activation=tf.nn.softmax))\n",
    "        \n",
    "        # Compile the model with the specified loss function, metrics, and learning rate\n",
    "        model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr),\n",
    "                      loss='categorical_crossentropy',\n",
    "                      metrics=[MultiClassFBeta(n_class=self.n_classes), 'accuracy'])\n",
    "        \n",
    "        # Print model architecture\n",
    "        print(model.summary())\n",
    "        \n",
    "        return model\n",
    "\n",
    "    def fit(self, hp, model, *args, **kwargs):\n",
    "        \n",
    "        '''\n",
    "        Fit model on data and tune batch size\n",
    "        '''\n",
    "        \n",
    "        return model.fit(\n",
    "            *args,\n",
    "            batch_size=hp.Int(\"batch_size\", min_value=16, max_value=126, step=8),\n",
    "            **kwargs,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131b144d",
   "metadata": {},
   "source": [
    "## Training pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "abc3fe50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_model(train_X, train_Y, test_X, test_Y, obj, tuning_dir=None, project_name='CNN', \n",
    "               epochs=20, patience=3, search_type='Bayesian', \n",
    "               max_trials=10, per_trial=2, bayesian_beta=2, new_search=False):\n",
    "    \n",
    "    '''\n",
    "    Function to perform hyperparameter search.\n",
    "    \n",
    "    Params\n",
    "    ------\n",
    "    train_X : np.array\n",
    "        Train dataset feature matrix\n",
    "    train_Y : np.array\n",
    "        Train dataset labels matrix\n",
    "    test_X : np.array\n",
    "        Test dataset feature matrix\n",
    "    test_Y : np.array\n",
    "        Test dataset labels matrix\n",
    "    obj: str | keras_tuner.Objective\n",
    "        The objective to optimize for\n",
    "    tuning_dir: str\n",
    "        Path to store tuning trials (defaults to 'path/to/current/parent_directory/model_tuning/')\n",
    "    project_name: str\n",
    "        Directory under tuning_dir to store model tuning results (defaults to 'CNN')\n",
    "    epochs: int\n",
    "        Max number of epochs to train (defaults to 20)\n",
    "    patience: int\n",
    "        Patience for EarlyStopping callback (defaults to 3)\n",
    "    search_type: str\n",
    "        Hyperparameter search type, either 'Random' or 'Bayesian' (defaults to 'Bayesian')\n",
    "    max_trials: int\n",
    "        Maximum number of search trials (defaults to 10)\n",
    "    per_trial: int\n",
    "        The number of models that should be built and fit for each trial (defaults to 2)\n",
    "    bayesian_beta: int\n",
    "        The balancing factor of exploration and exploitation. \n",
    "        The larger it is, the more explorative it is. (defaults to 2)\n",
    "    new_search: bool\n",
    "        Whether to overwrite the previous results in the same directory \n",
    "        or resume the previous search. (defaults to False)\n",
    "\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    CNN_tuner: keras_tuner\n",
    "        The fitted Keras Tuner that stores the results of the \n",
    "        hyperparameter tuning and the associated models.\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    # Get input and output shapes for the CNN model\n",
    "    n_features = train_X.shape[-1]\n",
    "    n_classes = train_Y.shape[-1]\n",
    "    \n",
    "    # Specify the default tuning directory\n",
    "    if not tuning_dir:\n",
    "        tuning_dir = os.path.join(os.path.dirname(os.getcwd()), \"model_tuning\")\n",
    "        tuning_dir\n",
    "\n",
    "    # Use GPU \n",
    "    with tf.device('/device:GPU:0'):\n",
    "        \n",
    "        model = CNNHyperModel(n_features=n_features, n_classes=n_classes)\n",
    "        \n",
    "        # Random search\n",
    "        if search_type=='Random':\n",
    "            CNN_tuner = keras_tuner.RandomSearch(\n",
    "                hypermodel=model,\n",
    "                objective=keras_tuner.Objective(\"val_macro_f1\", direction=\"max\"),\n",
    "                max_trials=max_trials,\n",
    "                executions_per_trial=per_trial,\n",
    "                overwrite=new_search,\n",
    "                directory=tuning_dir,\n",
    "                project_name=project_name,\n",
    "            )\n",
    "        \n",
    "        \n",
    "        # BayesianSearch\n",
    "        elif search_type=='Bayesian':\n",
    "                CNN_tuner = keras_tuner.BayesianOptimization(\n",
    "                hypermodel=model,\n",
    "                objective=keras_tuner.Objective(\"val_macro_f1\", direction=\"max\"),\n",
    "                max_trials=max_trials,\n",
    "                beta=bayesian_beta,\n",
    "                executions_per_trial=per_trial,\n",
    "                overwrite=new_search,\n",
    "                directory=tuning_dir,\n",
    "                project_name=project_name,\n",
    "            )\n",
    "        \n",
    "        # If neither search type is specified, raise an error\n",
    "        else:\n",
    "            raise ValueError(\"search_type must be either 'Random' or 'Bayesian'\")\n",
    "            \n",
    "        # Fit the hyperparameter tuner\n",
    "        CNN_tuner.search(x=train_X, y=train_Y, \n",
    "                         verbose=2, validation_data=(test_X, test_Y), \n",
    "                         epochs=epochs, callbacks=[keras.callbacks.EarlyStopping('val_macro_f1', \n",
    "                                                                             patience=patience, \n",
    "                                                                             mode='max', \n",
    "                                                                             restore_best_weights=True)]\n",
    "                        )\n",
    "        \n",
    "    return CNN_tuner\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c06fde5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_best_models(tuner, model_names, n_models=1, model_dir=None):\n",
    "    \n",
    "    '''\n",
    "    Save the best N models to a directory and return the save path\n",
    "    '''\n",
    "    \n",
    "    # Get the best N models\n",
    "    best_models = tuner.get_best_models()[:n_models]\n",
    "    print(best_models)\n",
    "\n",
    "    # Default model directory\n",
    "    if not model_dir:\n",
    "        model_dir = os.path.join(os.path.dirname(os.getcwd()), \"models\")\n",
    "        \n",
    "    if isinstance(model_names, str):\n",
    "        model_names = [model_names]\n",
    "    \n",
    "    print(model_names)\n",
    "    \n",
    "    # Save the best N models\n",
    "    for model, model_name in zip(best_models, model_names):\n",
    "        save_dir = os.path.join(model_dir, model_name)\n",
    "        model.save(save_dir)\n",
    "        \n",
    "    return save_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aBgw5K1_CmvK",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 748
    },
    "id": "aBgw5K1_CmvK",
    "outputId": "59b5f109-798d-47e9-b11d-7d6112c85a98",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Define hyperparameter tuning params\n",
    "results_dir = 'CNN_Nbands_wlake' \n",
    "epochs=20\n",
    "max_trials=20\n",
    "new_search=True\n",
    "per_trial=1\n",
    "beta=2.1\n",
    "objective = keras_tuner.Objective(\"val_macro_f1\", direction=\"max\")\n",
    "\n",
    "# Start hyperparameter search\n",
    "CNN_tuner = tune_model(conv_train_X, conv_sparse_train_Y, conv_test_X, conv_sparse_test_Y,\n",
    "                       objective, project_name=results_dir, epochs=epochs, bayesian_beta=beta,\n",
    "                       max_trials=max_trials, per_trial=per_trial, new_search=new_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39L_mkUYavGL",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "39L_mkUYavGL",
    "outputId": "ac07a45b-fd6d-4017-c8a5-61496b3b1c4c",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Save the best performing model\n",
    "model_name = f'{results_dir}_{time():.0f}'\n",
    "save_dir = save_best_models(CNN_tuner, model_name)\n",
    "\n",
    "print(f\"Best N models saved at: {save_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33340e39",
   "metadata": {},
   "source": [
    "## Check Hyperparamater Tuning Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "64d6b32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_tuning_results(trial_dict):\n",
    "    trial_df = pd.DataFrame(trial_dict)\n",
    "        \n",
    "    cols = trial_df.columns.tolist()\n",
    "    metrics = ['macro_f1', 'accuracy']\n",
    "    for m in metrics:\n",
    "        cols.remove(m)\n",
    "\n",
    "    cols = cols + metrics\n",
    "    trial_df = trial_df[cols]\n",
    "\n",
    "    df = trial_df.sort_values(by='macro_f1')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "235934e9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_tuning_results(model_path):\n",
    "\n",
    "    trial_dict = {}\n",
    "    trial_count = 0\n",
    "    \n",
    "    for item in os.listdir(model_path):\n",
    "        path = os.path.join(model_path, item)\n",
    "        if os.path.isdir(path):\n",
    "            f = open(os.path.join(path, 'trial.json'))\n",
    "            data = json.load(f)\n",
    "\n",
    "            # Track existing keys to add any None values\n",
    "            existing_keys = set(trial_dict.keys())\n",
    "\n",
    "            temp_dict = data['hyperparameters']['values']\n",
    "\n",
    "            macro_f1 = data['metrics']['metrics'].get('val_macro_f1', 0)\n",
    "            accuracy = data['metrics']['metrics'].get('val_accuracy', 0)\n",
    "            \n",
    "            if macro_f1:\n",
    "                macro_f1 = macro_f1['observations'][0]['value'][0]\n",
    "            if accuracy:\n",
    "                accuracy = accuracy['observations'][0]['value'][0]\n",
    "                \n",
    "            temp_dict['macro_f1'] = macro_f1\n",
    "            temp_dict['accuracy'] = accuracy\n",
    "\n",
    "            for k,v in temp_dict.items():\n",
    "                if not trial_dict.get(k):\n",
    "                    trial_dict[k] = []\n",
    "\n",
    "                    # Append all None for previous trials\n",
    "                    for i in range(trial_count):\n",
    "                        trial_dict[k].append(None)\n",
    "\n",
    "                trial_dict[k].append(v)\n",
    "\n",
    "                if k in existing_keys:\n",
    "                    existing_keys.remove(k)\n",
    "\n",
    "            if existing_keys:\n",
    "                for k in existing_keys:\n",
    "                    trial_dict[k].append(None)\n",
    "\n",
    "            # Update counter\n",
    "            trial_count += 1\n",
    "\n",
    "    df = convert_tuning_results(trial_dict)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d17fe582",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hidden_nodes</th>\n",
       "      <th>activation</th>\n",
       "      <th>dropout_rate</th>\n",
       "      <th>lr</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>macro_f1</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.0300</td>\n",
       "      <td>16</td>\n",
       "      <td>0.029853</td>\n",
       "      <td>0.098369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0300</td>\n",
       "      <td>16</td>\n",
       "      <td>0.072060</td>\n",
       "      <td>0.145274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>88</td>\n",
       "      <td>0.235266</td>\n",
       "      <td>0.269199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.0060</td>\n",
       "      <td>120</td>\n",
       "      <td>0.604550</td>\n",
       "      <td>0.751669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>20</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>120</td>\n",
       "      <td>0.606146</td>\n",
       "      <td>0.792507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>64</td>\n",
       "      <td>0.756491</td>\n",
       "      <td>0.821690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>32</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>64</td>\n",
       "      <td>0.836103</td>\n",
       "      <td>0.866926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>32</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>120</td>\n",
       "      <td>0.841142</td>\n",
       "      <td>0.862142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>32</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>16</td>\n",
       "      <td>0.851653</td>\n",
       "      <td>0.881726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>32</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>120</td>\n",
       "      <td>0.856703</td>\n",
       "      <td>0.882175</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   hidden_nodes activation  dropout_rate      lr  batch_size  macro_f1  \\\n",
       "2             4       relu          0.45  0.0300          16  0.029853   \n",
       "4            32       tanh          0.00  0.0300          16  0.072060   \n",
       "3             4       tanh          0.30  0.0003          88  0.235266   \n",
       "0            32       relu          0.30  0.0060         120  0.604550   \n",
       "9            20       tanh          0.00  0.0001         120  0.606146   \n",
       "1            32       relu          0.30  0.0001          64  0.756491   \n",
       "5            32       relu          0.00  0.0001          64  0.836103   \n",
       "6            32       relu          0.00  0.0001         120  0.841142   \n",
       "8            32       relu          0.00  0.0001          16  0.851653   \n",
       "7            32       relu          0.00  0.0100         120  0.856703   \n",
       "\n",
       "   accuracy  \n",
       "2  0.098369  \n",
       "4  0.145274  \n",
       "3  0.269199  \n",
       "0  0.751669  \n",
       "9  0.792507  \n",
       "1  0.821690  \n",
       "5  0.866926  \n",
       "6  0.862142  \n",
       "8  0.881726  \n",
       "7  0.882175  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = '../model_tuning/CNN_nbands/'\n",
    "df = get_tuning_results(model_path)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac4067a",
   "metadata": {
    "id": "1ac4067a"
   },
   "source": [
    "## EEificiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "xNBNYHjGUeXG",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xNBNYHjGUeXG",
    "outputId": "e449f510-ca96-4c3e-c3d1-9954e14ae592"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'{\"serving_default_input_1:0\": \"array\"}'\n",
      "'{\"StatefulPartitionedCall:0\": \"output\"}'\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.tools import saved_model_utils\n",
    "\n",
    "meta_graph_def = saved_model_utils.get_meta_graph_def(save_dir, 'serve')\n",
    "inputs = meta_graph_def.signature_def['serving_default'].inputs\n",
    "outputs = meta_graph_def.signature_def['serving_default'].outputs\n",
    "\n",
    "# Just get the first thing(s) from the serving signature def.  i.e. this\n",
    "# model only has a single input and a single output.\n",
    "input_name = None\n",
    "for k,v in inputs.items():\n",
    "  input_name = v.name\n",
    "  break\n",
    "\n",
    "output_name = None\n",
    "for k,v in outputs.items():\n",
    "  output_name = v.name\n",
    "  break\n",
    "\n",
    "# Make a dictionary that maps Earth Engine outputs and inputs to\n",
    "# AI Platform inputs and outputs, respectively.\n",
    "import json\n",
    "input_dict = \"'\" + json.dumps({input_name: \"array\"}) + \"'\"\n",
    "output_dict = \"'\" + json.dumps({output_name: \"output\"}) + \"'\"\n",
    "print(input_dict)\n",
    "print(output_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "lGq7v9tQcwuK",
   "metadata": {
    "id": "lGq7v9tQcwuK"
   },
   "outputs": [],
   "source": [
    "# Put the EEified model in the appropriate bucket and API name\n",
    "PROJECT = 'w210-351617'\n",
    "OUTPUT_BUCKET = 'test-tf-gee'\n",
    "EEIFIED_DIR = 'gs://' + OUTPUT_BUCKET + f'/{results_dir}'\n",
    "\n",
    "MODEL_NAME = f'{results_dir}v2'\n",
    "VERSION_NAME = 'v0'\n",
    "REGION = 'us-central1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f1db4f2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gs://test-tf-gee/CNN_Nbands_wlake_model'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EEIFIED_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "1WNSCgA6Uswh",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1WNSCgA6Uswh",
    "outputId": "92905efd-7461-4963-fe63-5eee87d61ab0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully saved project id\n",
      "Warning: TensorFlow Addons not found. Models that use non-standard ops may not work.\n",
      "Success: model at 'gs://test-tf-gee/CNN_Nbands_wlake_model' is ready to be hosted in AI Platform.\n"
     ]
    }
   ],
   "source": [
    "# Run the model prepare commands\n",
    "!earthengine set_project {PROJECT}\n",
    "!earthengine model prepare --source_dir {save_dir} --dest_dir {EEIFIED_DIR} --input {input_dict} --output {output_dict}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "68b2a383",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "68b2a383",
    "outputId": "dd1c9583-b4ee-48e7-dbe5-c7886733fe65",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using endpoint [https://us-central1-ml.googleapis.com/]\n",
      "Created ai platform model [projects/w210-351617/models/CNN_Nbands_wlake_modelv2].\n",
      "Using endpoint [https://us-central1-ml.googleapis.com/]\n",
      "Creating version (this might take a few minutes)......done.                    \n"
     ]
    }
   ],
   "source": [
    "# Create API endpoint hosted on Google AI Platform\n",
    "!gcloud ai-platform models create {MODEL_NAME} \\\n",
    "  --project {PROJECT} \\\n",
    "  --region {REGION}\n",
    "\n",
    "!gcloud ai-platform versions create {VERSION_NAME} \\\n",
    "  --project {PROJECT} \\\n",
    "  --region {REGION} \\\n",
    "  --model {MODEL_NAME} \\\n",
    "  --origin {EEIFIED_DIR} \\\n",
    "  --framework \"TENSORFLOW\" \\\n",
    "  --runtime-version=2.3 \\\n",
    "  --python-version=3.7"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "data_preprocessing+NN_tuning_ST.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "4b7582aa96ab4a52835aefa67a9e1b78": {
     "model_module": "jupyter-leaflet",
     "model_module_version": "^0.17.0",
     "model_name": "LeafletMapModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "jupyter-leaflet",
      "_model_module_version": "^0.17.0",
      "_model_name": "LeafletMapModel",
      "_view_count": null,
      "_view_module": "jupyter-leaflet",
      "_view_module_version": "^0.17.0",
      "_view_name": "LeafletMapView",
      "bottom": 0,
      "bounce_at_zoom_limits": true,
      "box_zoom": true,
      "center": [
       20,
       0
      ],
      "close_popup_on_click": true,
      "controls": [
       "IPY_MODEL_f407b3b2aabc4a668d073134666ad7eb",
       "IPY_MODEL_e636c61ebe194a288dbad13e7f065b74",
       "IPY_MODEL_a9c7613569174982b5861a86de416c4b",
       "IPY_MODEL_8a49174c73704adfb73fc92e533e2198",
       "IPY_MODEL_e21d1e9d2321493aae367b9264c6bd3a",
       "IPY_MODEL_42a43a59ac5b403389a61a2c6a135ce8",
       "IPY_MODEL_54d651e3bc9f40c091ab118a6d45d6f2",
       "IPY_MODEL_1ec93dd741bf42ca8ccd98e991929c55"
      ],
      "crs": {
       "custom": false,
       "name": "EPSG3857"
      },
      "default_style": "IPY_MODEL_56c76996b3284e6e9f00881f6a6a3a65",
      "double_click_zoom": true,
      "dragging": true,
      "dragging_style": "IPY_MODEL_90834ecc6d834efba53762d767ebc907",
      "east": 0,
      "fullscreen": false,
      "inertia": true,
      "inertia_deceleration": 3000,
      "inertia_max_speed": 1500,
      "interpolation": "bilinear",
      "keyboard": true,
      "keyboard_pan_offset": 80,
      "keyboard_zoom_offset": 1,
      "layers": [
       "IPY_MODEL_406f2816e09d495cb4bcdcb4bbca8061",
       "IPY_MODEL_6fc89369dc8545d3a3eb199031da2b44",
       "IPY_MODEL_e9f56479c5bb402b911e41508823d8be",
       "IPY_MODEL_05d5f9e70da64ee385afc81af124dc8b"
      ],
      "layout": "IPY_MODEL_84dcb6fceafb4dfba5d93b76cd2a2e5a",
      "left": 9007199254740991,
      "max_zoom": 24,
      "min_zoom": null,
      "modisdate": "2022-07-08",
      "north": 0,
      "options": [
       "bounce_at_zoom_limits",
       "box_zoom",
       "center",
       "close_popup_on_click",
       "double_click_zoom",
       "dragging",
       "fullscreen",
       "inertia",
       "inertia_deceleration",
       "inertia_max_speed",
       "interpolation",
       "keyboard",
       "keyboard_pan_offset",
       "keyboard_zoom_offset",
       "max_zoom",
       "min_zoom",
       "prefer_canvas",
       "scroll_wheel_zoom",
       "tap",
       "tap_tolerance",
       "touch_zoom",
       "world_copy_jump",
       "zoom",
       "zoom_animation_threshold",
       "zoom_delta",
       "zoom_snap"
      ],
      "panes": {},
      "prefer_canvas": false,
      "right": 0,
      "scroll_wheel_zoom": true,
      "south": 0,
      "style": "IPY_MODEL_bf93fa7864f24136849e99eb21f36e91",
      "tap": true,
      "tap_tolerance": 15,
      "top": 9007199254740991,
      "touch_zoom": true,
      "west": 0,
      "window_url": "",
      "world_copy_jump": false,
      "zoom": 2,
      "zoom_animation_threshold": 4,
      "zoom_delta": 1,
      "zoom_snap": 1
     }
    },
    "57521180d256424c974c1184813bf5f4": {
     "model_module": "jupyter-leaflet",
     "model_module_version": "^0.17.0",
     "model_name": "LeafletMapModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "jupyter-leaflet",
      "_model_module_version": "^0.17.0",
      "_model_name": "LeafletMapModel",
      "_view_count": null,
      "_view_module": "jupyter-leaflet",
      "_view_module_version": "^0.17.0",
      "_view_name": "LeafletMapView",
      "bottom": 0,
      "bounce_at_zoom_limits": true,
      "box_zoom": true,
      "center": [
       20,
       0
      ],
      "close_popup_on_click": true,
      "controls": [
       "IPY_MODEL_c9c6de26ce2344cdb28d40828c5c0a44",
       "IPY_MODEL_dfecac8bb1404b80bb1193b78ab66d0d",
       "IPY_MODEL_320f6bbbb4fc4639aef5bb255cdb1606",
       "IPY_MODEL_bd9ef45459674181a5cf0ee3bd475dc6",
       "IPY_MODEL_c32e4cd0472645908d4cd8f26d464415",
       "IPY_MODEL_4d8ae2aac44946e68d28407e30a84785",
       "IPY_MODEL_83aef1cb3ffa4ca3958d1ba41e47225e",
       "IPY_MODEL_f8127a6e10c248ed9a19e36f262d7238"
      ],
      "crs": {
       "custom": false,
       "name": "EPSG3857"
      },
      "default_style": "IPY_MODEL_92d3b3aa3fa6489f957889931a5a74fb",
      "double_click_zoom": true,
      "dragging": true,
      "dragging_style": "IPY_MODEL_6941cd9f854f46ebb5918794c8d74f11",
      "east": 0,
      "fullscreen": false,
      "inertia": true,
      "inertia_deceleration": 3000,
      "inertia_max_speed": 1500,
      "interpolation": "bilinear",
      "keyboard": true,
      "keyboard_pan_offset": 80,
      "keyboard_zoom_offset": 1,
      "layers": [
       "IPY_MODEL_e08f1b425dd4434eb2f790e5a786fe6e",
       "IPY_MODEL_75e8619b04ee4debb4178374cca2ab3e",
       "IPY_MODEL_10d9755c15624490be027c05502d769a"
      ],
      "layout": "IPY_MODEL_435ea1de61004d51bdb9e67d43bbe2d0",
      "left": 9007199254740991,
      "max_zoom": 24,
      "min_zoom": null,
      "modisdate": "2022-07-08",
      "north": 0,
      "options": [
       "bounce_at_zoom_limits",
       "box_zoom",
       "center",
       "close_popup_on_click",
       "double_click_zoom",
       "dragging",
       "fullscreen",
       "inertia",
       "inertia_deceleration",
       "inertia_max_speed",
       "interpolation",
       "keyboard",
       "keyboard_pan_offset",
       "keyboard_zoom_offset",
       "max_zoom",
       "min_zoom",
       "prefer_canvas",
       "scroll_wheel_zoom",
       "tap",
       "tap_tolerance",
       "touch_zoom",
       "world_copy_jump",
       "zoom",
       "zoom_animation_threshold",
       "zoom_delta",
       "zoom_snap"
      ],
      "panes": {},
      "prefer_canvas": false,
      "right": 0,
      "scroll_wheel_zoom": true,
      "south": 0,
      "style": "IPY_MODEL_e8c98861804e4a46b5b5525263ed0e60",
      "tap": true,
      "tap_tolerance": 15,
      "top": 9007199254740991,
      "touch_zoom": true,
      "west": 0,
      "window_url": "",
      "world_copy_jump": false,
      "zoom": 2,
      "zoom_animation_threshold": 4,
      "zoom_delta": 1,
      "zoom_snap": 1
     }
    },
    "c9a017e6dd2f474b8e34648f641f72b5": {
     "model_module": "jupyter-leaflet",
     "model_module_version": "^0.17.0",
     "model_name": "LeafletMapModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "jupyter-leaflet",
      "_model_module_version": "^0.17.0",
      "_model_name": "LeafletMapModel",
      "_view_count": null,
      "_view_module": "jupyter-leaflet",
      "_view_module_version": "^0.17.0",
      "_view_name": "LeafletMapView",
      "bottom": 0,
      "bounce_at_zoom_limits": true,
      "box_zoom": true,
      "center": [
       0,
       0
      ],
      "close_popup_on_click": true,
      "controls": [
       "IPY_MODEL_3eaa35cb1a1342f6b7c5fcd203e4c9d8",
       "IPY_MODEL_051655ef7768437a885746163e151519"
      ],
      "crs": {
       "custom": false,
       "name": "EPSG3857"
      },
      "default_style": "IPY_MODEL_843b0e1a73694c1bade8660e90a770a0",
      "double_click_zoom": true,
      "dragging": true,
      "dragging_style": "IPY_MODEL_435ad546d1ad4b1da7cfaf8fd3b7a90c",
      "east": 0,
      "fullscreen": false,
      "inertia": true,
      "inertia_deceleration": 3000,
      "inertia_max_speed": 1500,
      "interpolation": "bilinear",
      "keyboard": true,
      "keyboard_pan_offset": 80,
      "keyboard_zoom_offset": 1,
      "layers": [
       "IPY_MODEL_84550e6cafb64e9b969488fe9239d267"
      ],
      "layout": "IPY_MODEL_b486a4cf9c5248fd92128d7a6d176e06",
      "left": 9007199254740991,
      "max_zoom": null,
      "min_zoom": null,
      "modisdate": "2022-07-08",
      "north": 0,
      "options": [
       "bounce_at_zoom_limits",
       "box_zoom",
       "center",
       "close_popup_on_click",
       "double_click_zoom",
       "dragging",
       "fullscreen",
       "inertia",
       "inertia_deceleration",
       "inertia_max_speed",
       "interpolation",
       "keyboard",
       "keyboard_pan_offset",
       "keyboard_zoom_offset",
       "max_zoom",
       "min_zoom",
       "prefer_canvas",
       "scroll_wheel_zoom",
       "tap",
       "tap_tolerance",
       "touch_zoom",
       "world_copy_jump",
       "zoom",
       "zoom_animation_threshold",
       "zoom_delta",
       "zoom_snap"
      ],
      "panes": {},
      "prefer_canvas": false,
      "right": 0,
      "scroll_wheel_zoom": false,
      "south": 0,
      "style": "IPY_MODEL_1756055d52a24290902d641bc328307f",
      "tap": true,
      "tap_tolerance": 15,
      "top": 9007199254740991,
      "touch_zoom": true,
      "west": 0,
      "window_url": "",
      "world_copy_jump": false,
      "zoom": null,
      "zoom_animation_threshold": 4,
      "zoom_delta": 1,
      "zoom_snap": 1
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
