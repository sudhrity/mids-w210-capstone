{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae68adb4",
   "metadata": {},
   "source": [
    "# Google Earth Engine Panel Data Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e611da9",
   "metadata": {},
   "source": [
    "## Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e29866a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install geemap\n",
    "#!pip install ee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0028757",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install uszipcode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f374eaf6",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'StringIO'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-9acb72286e79>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#GEE specific\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mee\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgeemap\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/ee/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmain\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/ee/main.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mplistlib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mStringIO\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mplatform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'StringIO'"
     ]
    }
   ],
   "source": [
    "#GEE specific\n",
    "import ee\n",
    "import geemap\n",
    "import math\n",
    "\n",
    "#plotting and functions\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "from time import time\n",
    "\n",
    "# Postgres\n",
    "import psycopg2\n",
    "\n",
    "# Zip code info\n",
    "from uszipcode import SearchEngine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4050fd37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize Google Earth Engine\n",
    "#ee.Authenticate() #just needed the 1st time\n",
    "ee.Initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4219dc52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if geemap is working as intended - plot the leaflet map\n",
    "Map = geemap.Map()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc8c8221",
   "metadata": {},
   "source": [
    "## Load Feature Collection - Shapefiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b9e062f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data loads\n",
    "\n",
    "#loads feature collection data from Google Earth Engine - We can also upload other feature collections\n",
    "counties = ee.FeatureCollection(\"TIGER/2018/Counties\")\n",
    "\n",
    "#filter LA County\n",
    "la_county = counties.filter(ee.Filter.eq('NAME', 'Los Angeles'))\n",
    "sc_county = counties.filter(ee.Filter.eq('NAME', 'Santa Clara'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "980becb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<ee.featurecollection.FeatureCollection at 0x7f368a207cd0>,\n",
       " <ee.featurecollection.FeatureCollection at 0x7f368a2079d0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "la_county, sc_county"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9fb14528",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Income Data\n",
    "la_county_income = ee.FeatureCollection(\"projects/california-lawn-detection/assets/lacountyincome-final\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82e8eb5",
   "metadata": {},
   "source": [
    "## Load NAIP Imagery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ccaec9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_3bands(image, band):\n",
    "    i_8_bit = image.select(band).toUint8()\n",
    "    square = ee.Kernel.square(**{'radius': 4})\n",
    "    entropy = i_8_bit.entropy(square)\n",
    "    glcm = i_8_bit.glcmTexture(**{'size': 4})\n",
    "    contrast = glcm.select(str(band)+'_contrast')\n",
    "    \n",
    "    # Create a list of weights for a 9x9 kernel.\n",
    "    list = [1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
    "    # The center of the kernel is zero.\n",
    "    centerList = [1, 1, 1, 1, 0, 1, 1, 1, 1]\n",
    "    # Assemble a list of lists: the 9x9 kernel weights as a 2-D matrix.\n",
    "    lists = [list, list, list, list, centerList, list, list, list, list]\n",
    "    # Create the kernel from the weights.\n",
    "    # Non-zero weights represent the spatial neighborhood.\n",
    "    kernel = ee.Kernel.fixed(9, 9, lists, -4, -4, False)\n",
    "    neighs = i_8_bit.neighborhoodToBands(kernel)\n",
    "    gearys = i_8_bit.subtract(neighs).pow(2).reduce(ee.Reducer.sum()).divide(math.pow(9, 2))\n",
    "    image = image.addBands(entropy.rename(str(band)+'_Entropy')).addBands(contrast.rename(str(band)+'_Contrast')).addBands(gearys.rename(str(band)+'_Gearys'))   \n",
    "    return image\n",
    "\n",
    "def add_neighborhood_bands(image):\n",
    "    bands = ['R', 'G', 'B', 'N']\n",
    "    for band in bands:\n",
    "        image = apply_3bands(image, band)\n",
    "    return image\n",
    "    \n",
    "def add_NDVI(image):\n",
    "    image = image.addBands(image.normalizedDifference(['N','R']).rename('NDVI'))\n",
    "    return image\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6f6ffc5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_images(param_dict):\n",
    "    source_image_collection = param_dict['source_image_collection']\n",
    "    years = param_dict['years']\n",
    "    counties = param_dict['counties']\n",
    "\n",
    "    image_names = []\n",
    "    images = []\n",
    "\n",
    "    combos = list(itertools.product(years, counties.keys()))\n",
    "    for i in combos:\n",
    "        year = str(i[0])\n",
    "        county = i[1]\n",
    "\n",
    "        image_name = str(i[0])+'_'+i[1]\n",
    "        image_names.append(image_name)\n",
    "\n",
    "        image = ee.ImageCollection(source_image_collection)\\\n",
    "                                .filterDate(f'{year}-01-01', f'{year}-12-31')\\\n",
    "                                .select(['R','G','B','N'])\\\n",
    "                                .median().clip(counties[county])\n",
    "        images.append(image)\n",
    "        images_with_3band = list(map(add_neighborhood_bands, images))\n",
    "        images_with_NDVI = list(map(add_NDVI, images_with_3band))\n",
    "    return dict(zip(image_names, images_with_NDVI))\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d7b71d",
   "metadata": {},
   "source": [
    "## Load Labeled Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ffe3f4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loading feature collections from Google Earth Engine\n",
    "\n",
    "water_1 = ee.FeatureCollection(\"projects/california-lawn-detection/assets/water_torrance_0610\")\n",
    "water_2 = ee.FeatureCollection(\"projects/california-lawn-detection/assets/water_torrance_0701_400\")\n",
    "vegetation_trees = ee.FeatureCollection(\"projects/california-lawn-detection/assets/trees_torrance\")\n",
    "vegetation_grass = ee.FeatureCollection(\"projects/california-lawn-detection/assets/grass_torrance\").limit(400)\n",
    "turf_1 = ee.FeatureCollection(\"projects/california-lawn-detection/assets/turf_torrance1\")\n",
    "turf_2 = ee.FeatureCollection(\"projects/california-lawn-detection/assets/turf_torrance2\")\n",
    "impervious_1 = ee.FeatureCollection(\"projects/california-lawn-detection/assets/impervious_torrance1\").limit(35)\n",
    "impervious_2 = ee.FeatureCollection(\"projects/california-lawn-detection/assets/impervious_torrance2\").limit(35)\n",
    "soil = ee.FeatureCollection(\"projects/california-lawn-detection/assets/soil_reduced_070222\")\n",
    "\n",
    "water = water_1.merge(water_2)\n",
    "turf = turf_1.merge(turf_2)\n",
    "impervious= impervious_1.merge(impervious_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a8398fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conditional_water(feat):\n",
    "    return ee.Algorithms.If(ee.Number(feat.get('landcover')).eq(1),feat.set({'landcover': 0}),feat)\n",
    "\n",
    "def conditional_trees(feat):\n",
    "    return ee.Algorithms.If(ee.Number(feat.get('landcover')).eq(2),feat.set({'landcover': 1}),feat)\n",
    "\n",
    "def conditional_grass(feat):\n",
    "    return ee.Algorithms.If(ee.Number(feat.get('landcover')).eq(3),feat.set({'landcover': 2}),feat)\n",
    "\n",
    "def conditional_turf(feat):\n",
    "    return ee.Algorithms.If(ee.Number(feat.get('landcover')).eq(4),feat.set({'landcover': 3}),feat)\n",
    "\n",
    "def conditional_impervious(feat):\n",
    "    return ee.Algorithms.If(ee.Number(feat.get('landcover')).eq(6),feat.set({'landcover': 4}),feat)\n",
    "\n",
    "def conditional_soil(feat):\n",
    "    return ee.Algorithms.If(ee.Number(feat.get('landcover')).eq(7),feat.set({'landcover': 5}),feat)\n",
    "\n",
    "water_tr = water.map(conditional_water)\n",
    "trees_tr = vegetation_trees.map(conditional_trees)\n",
    "grass_tr = vegetation_grass.map(conditional_grass)\n",
    "turf_tr = turf.map(conditional_turf)\n",
    "impervious_tr = impervious.map(conditional_impervious)\n",
    "soil_tr = soil.map(conditional_soil)\n",
    "\n",
    "LABELED_SET = water_tr.merge(trees_tr).merge(grass_tr).merge(turf_tr).merge(impervious_tr).merge(soil_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9131d938",
   "metadata": {},
   "outputs": [],
   "source": [
    "water_test = ee.FeatureCollection(\"projects/california-lawn-detection/assets/water_test\")\n",
    "vegetation_trees_test = ee.FeatureCollection(\"projects/california-lawn-detection/assets/trees_test\")\n",
    "vegetation_grass_test  = ee.FeatureCollection(\"projects/california-lawn-detection/assets/grass_test\")\n",
    "turf_test  = ee.FeatureCollection(\"projects/california-lawn-detection/assets/turf_test\")\n",
    "impervious_test  = ee.FeatureCollection(\"projects/california-lawn-detection/assets/impervious_reduced_test\")\n",
    "soil_test  = ee.FeatureCollection(\"projects/california-lawn-detection/assets/soil_reduced_070222\")\n",
    "\n",
    "TEST_SET = water_test.merge(vegetation_trees_test).merge(vegetation_grass_test).merge(turf_test).merge(impervious_test).merge(soil_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "074e81c0",
   "metadata": {},
   "source": [
    "## Build Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ed4501b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_image_params = {\n",
    "        'source_image_collection' : 'USDA/NAIP/DOQQ',\n",
    "        'years' : [2020],\n",
    "        'counties': {'la_county': la_county}\n",
    "         }\n",
    "\n",
    "TRAINING_IMAGE = get_images(training_image_params)['2020_la_county']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7ce39c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "Map.addLayer(TRAINING_IMAGE, {}, 'TRAINING_IMAGE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5e336cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overlay the points on the imagery to get training.\n",
    "LABEL = 'landcover'\n",
    "BANDS = ['R', \n",
    "         'G', \n",
    "         'B', \n",
    "         'N', \n",
    "         'NDVI',\n",
    "         'N_Entropy', \n",
    "         'N_Contrast', \n",
    "         'N_Gearys']\n",
    "\n",
    "train_data = TRAINING_IMAGE.select(BANDS).sampleRegions(**{\n",
    "  'collection': LABELED_SET,\n",
    "  'properties': [LABEL],\n",
    "  'scale': 1\n",
    "})\n",
    "\n",
    "test_data = TRAINING_IMAGE.select(BANDS).sampleRegions(**{\n",
    "  'collection': TEST_SET,\n",
    "  'properties': [LABEL],\n",
    "  'scale': 1\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "13f6653b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Training Set Size in Pixels\", train_data.aggregate_count('R').getInfo())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "89e4d5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Test Set Size in Pixels\", test_data.aggregate_count('R').getInfo())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68482e63",
   "metadata": {},
   "source": [
    "## Machine Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "faeff825",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ee.Classifier at 0x7f368a1d1b20>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = ee.Classifier.smileRandomForest(numberOfTrees = 230, minLeafPopulation = 50, bagFraction= 0.6)\\\n",
    "                   .train(train_data, LABEL, BANDS)\n",
    "clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "93c043df",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_image_classified = TRAINING_IMAGE.select(BANDS)\\\n",
    "                                          .classify(clf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9871b67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "legend_keys = ['water', 'vegetation_trees', 'vegetation_grass', 'turf','impervious','soil']\n",
    "legend_colors = ['#0B6AEF', '#097407', '#0CE708', '#8C46D2' ,' #A1A8AF','#D47911']\n",
    "\n",
    "Map.addLayer(training_image_classified, {'min': 0, 'max': 5, 'palette': legend_colors}, 'Classification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cd43dcf1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['classification']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_image_classified.bandNames().getInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9de8d0d5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "069e20dea0aa4b7cb77e0b833b6564df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[20, 0], controls=(WidgetControl(options=['position', 'transparent_bg'], widget=HBox(children=(Toggâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834d7efd",
   "metadata": {},
   "source": [
    "## Binary Classification and Area Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e4657b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def area_calculation(image, class_number, shape, pixel_scale = 20):\n",
    "\n",
    "    if type(shape) == str:\n",
    "        shape = la_county_income_zipcode.filter(ee.Filter.eq('ZipCode', shape))\n",
    "\n",
    "    areaImage = image.eq(class_number).multiply(ee.Image.pixelArea())\n",
    "\n",
    "    area = areaImage.reduceRegion(\n",
    "        reducer = ee.Reducer.sum(),\n",
    "        geometry = shape,\n",
    "        scale = pixel_scale,\n",
    "        maxPixels = 1e13)\n",
    "\n",
    "\n",
    "    area_sq_m = area.getInfo().get('classification')\n",
    "\n",
    "    area_sq_km = area_sq_m / 1e6\n",
    "\n",
    "    return area_sq_km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2d02b839",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ndvi_calculation(image, class_number, shape, ref_image, pixel_scale=1):\n",
    "    \n",
    "    if type(shape) == str:\n",
    "        shape = la_county_income_zipcode.filter(ee.Filter.eq('ZipCode', shape))\n",
    "        \n",
    "    ndvi = ref_image.normalizedDifference(['N', 'R'])\n",
    "    image_clipped = image.clip(shape)\n",
    "    \n",
    "    NDVI_for_class = ndvi.updateMask(image_clipped.select('classification').eq(class_number))\n",
    "    \n",
    "    reducer = ee.Reducer.mean()\\\n",
    "                        .combine(ee.Reducer.max(),sharedInputs=True)\\\n",
    "                        .combine(ee.Reducer.min(),sharedInputs=True)\n",
    "    \n",
    "    \n",
    "    qty = NDVI_for_class.reduceRegion(\n",
    "        reducer = reducer, \n",
    "        geometry = shape, \n",
    "        scale = pixel_scale, \n",
    "        maxPixels = 1e13)\n",
    "    return qty\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2adb5e30",
   "metadata": {},
   "source": [
    "### Create Panel Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5f18e2f9",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "#import parcel shapes so we can clip by residential areas\n",
    "\n",
    "la_parcel_shape_filtered = ee.FeatureCollection(\"projects/california-lawn-detection/assets/LA_County_Parcels_Shape\")\\\n",
    "                             .filter(ee.Filter.eq('UseType', 'Residential'))\n",
    "    \n",
    "la_parcel_res = la_parcel_shape_filtered.select(ee.List(['AIN', 'SitusCity','SitusZIP','SitusFullA']), \n",
    "                                                ee.List(['AIN', 'City','ZipCode','FullAddress']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7cfac749",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "#import zipcode shapes so we can clip by zipcodes\n",
    "\n",
    "la_county_income_zipcode2 = ee.FeatureCollection(\"projects/california-lawn-detection/assets/income_zipcode2019\")\n",
    "la_county_income_zipcode = la_county_income_zipcode2.select(ee.List(['zipcode', '2019zipcod','shape_area']), ee.List(['ZipCode', 'Median_Income','Area_sqft']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "62d08bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# function to run a select query and return rows in a pandas dataframe\n",
    "# pandas puts all numeric values from postgres to float\n",
    "# if it will fit in an integer, change it to integer\n",
    "#\n",
    "\n",
    "def my_select_query_pandas(query, rollback_before_flag, rollback_after_flag):\n",
    "    \"function to run a select query and return rows in a pandas dataframe\"\n",
    "    \n",
    "    if rollback_before_flag:\n",
    "        connection.rollback()\n",
    "    \n",
    "    df = pd.read_sql_query(query, connection)\n",
    "    \n",
    "    if rollback_after_flag:\n",
    "        connection.rollback()\n",
    "    \n",
    "    # fix the float columns that really should be integers\n",
    "    \n",
    "    for column in df:\n",
    "    \n",
    "        if df[column].dtype == \"float64\":\n",
    "\n",
    "            fraction_flag = False\n",
    "\n",
    "            for value in df[column].values:\n",
    "                \n",
    "                if not np.isnan(value):\n",
    "                    if value - math.floor(value) != 0:\n",
    "                        fraction_flag = True\n",
    "\n",
    "            if not fraction_flag:\n",
    "                df[column] = df[column].astype('Int64')\n",
    "    \n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fcd972f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "connection = psycopg2.connect(\n",
    "    user = \"postgres\",\n",
    "    password = \"&j>n!_nL]k&wWdE>*TVds4P6\",\n",
    "    host = \"3.239.228.42\",\n",
    "    port = \"5432\",\n",
    "    database = \"postgres\"\n",
    ")\n",
    "cursor = connection.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "adfa80af",
   "metadata": {},
   "outputs": [],
   "source": [
    "rollback_before_flag = True\n",
    "rollback_after_flag = True\n",
    "\n",
    "query = \"\"\"\n",
    "\n",
    "select zipcode \n",
    "from zipcode_detail\n",
    "where county = 'Los Angeles County'\n",
    "order by zipcode;\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "zipcodes_df = my_select_query_pandas(query, rollback_before_flag, rollback_after_flag)\n",
    "\n",
    "zipcode_list = zipcodes_df['zipcode'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1deb6bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sr = SearchEngine()\n",
    "\n",
    "def insert_panel_zipcode(year, zipcode, water_area, tree_area, grass_area, turf_area, \n",
    "                        impervious_area, soil_area, total_area,\n",
    "                        tree_ndvi_mean, tree_ndvi_max, tree_ndvi_min,\n",
    "                        grass_ndvi_mean, grass_ndvi_max, grass_ndvi_min):\n",
    "\n",
    "    connection.rollback()\n",
    "    \n",
    "    z = sr.by_zipcode(zipcode)\n",
    "    city = z.major_city\n",
    "    state = z.state_abbr\n",
    "    print(\"state\", state)\n",
    "    county = z.county\n",
    "    median_income = z.median_household_income\n",
    "    \n",
    "    panel_zipcode_dict ={ 'item' : (state, \n",
    "                                    county, \n",
    "                                    zipcode, \n",
    "                                    city, \n",
    "                                    year, \n",
    "                                    round(total_area, 8),\n",
    "                                    round(water_area, 8),\n",
    "                                    round(grass_area, 8), \n",
    "                                    round(tree_area, 8),\n",
    "                                    0.0, \n",
    "                                    round(impervious_area, 8), \n",
    "                                    round(soil_area, 8), \n",
    "                                    round(turf_area,  8),\n",
    "                                    median_income, \n",
    "                                    0.0,\n",
    "                                    tree_ndvi_mean, \n",
    "                                    tree_ndvi_max, \n",
    "                                    tree_ndvi_min,\n",
    "                                    grass_ndvi_mean, \n",
    "                                    grass_ndvi_max, \n",
    "                                    grass_ndvi_min)\n",
    "    }\n",
    "\n",
    "    \n",
    "    print(panel_zipcode_dict)\n",
    "    \n",
    "    columns= panel_zipcode_dict.keys()\n",
    "    \n",
    "    for i in panel_zipcode_dict.values():\n",
    "        \n",
    "        query = '''\n",
    "\n",
    "        INSERT INTO panel_zipcode (state, \n",
    "                                    county, \n",
    "                                    zipcode, \n",
    "                                    city_neighborhood, \n",
    "                                    year, \n",
    "                                    polygon_area, \n",
    "                                    water_area, \n",
    "                                    lawn_area, \n",
    "                                    tree_area, \n",
    "                                    pv_area, \n",
    "                                    impervious_area, \n",
    "                                    soil_area, \n",
    "                                    turf_area, \n",
    "                                    median_income, \n",
    "                                    water_usage,\n",
    "                                    tree_ndvi_mean, \n",
    "                                    tree_ndvi_max, \n",
    "                                    tree_ndvi_min,\n",
    "                                    grass_ndvi_mean, \n",
    "                                    grass_ndvi_max, \n",
    "                                    grass_ndvi_min)\n",
    "            VALUES {}; '''.format(i)\n",
    "\n",
    "        try:\n",
    "            cursor.execute(query)\n",
    "        \n",
    "        except (Exception, psycopg2.DatabaseError) as error:\n",
    "            print(error)\n",
    "    \n",
    "        finally:\n",
    "        \n",
    "            if connection is not None:\n",
    "                connection.commit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fb1a95ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from psycopg2.extras import execute_values\n",
    "\n",
    "# zipcode = '90025'\n",
    "\n",
    "# def delete_panel_zipcode(zipcode):\n",
    "\n",
    "#     connection.rollback()\n",
    "    \n",
    "        \n",
    "#     query = \"DELETE FROM panel_zipcode WHERE zipcode IN ('90025')\"\n",
    "\n",
    "#     try:\n",
    "#         execute_values(cursor, query)\n",
    "#         connection.commit()\n",
    "        \n",
    "#     except (Exception, psycopg2.DatabaseError) as error:\n",
    "#         print(error)\n",
    "\n",
    "#     finally:\n",
    "\n",
    "#         if connection is not None:\n",
    "#             connection.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4a957252",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_inference(inference_params):\n",
    "    \n",
    "    #unpack inference parameter dictionary\n",
    "    inference_images = get_images(inference_params)\n",
    "    residential = inference_params['residential']\n",
    "    zipcode_list = inference_params['zipcodes']\n",
    "    ndvi = inference_params['ndvi']\n",
    "    zipcode_shape = inference_params['zipcode_shape']\n",
    "    residential_shape = inference_params['residential_shape']\n",
    "    \n",
    "    #add empty lists to data dictionary\n",
    "    dictionary = {}\n",
    "\n",
    "    base_keys = ['year','polygon','water_area','vegetation_trees_area', \n",
    "        'vegetation_grass_area', 'turf_area', 'impervious_area',\n",
    "        'soil_area', 'total_area']\n",
    "    \n",
    "    ndvi_keys = ['tree_ndvi_mean', 'tree_ndvi_max','tree_ndvi_min',\n",
    "       'grass_ndvi_mean', 'grass_ndvi_max','grass_ndvi_min']\n",
    "    \n",
    "    for i in base_keys:\n",
    "        dictionary[i] = []\n",
    "    if ndvi:\n",
    "        for i in ndvi_keys:\n",
    "            dictionary[i] = []\n",
    "    \n",
    "#     base_keys = ['year','polygon','water_area','vegetation_trees_area', \n",
    "#         'vegetation_grass_area', 'turf_area', 'impervious_area',\n",
    "#         'soil_area', 'total_area']\n",
    "    \n",
    "#     ndvi_keys = ['tree_ndvi_mean', 'tree_ndvi_max','tree_ndvi_min',\n",
    "#        'grass_ndvi_mean', 'grass_ndvi_max','grass_ndvi_min']\n",
    "    \n",
    "    #warning message about selected options\n",
    "    if inference_params['residential']:\n",
    "        print('CLIPPING AREA TO INCLUDE RESIDENTIAL AREAS ONLY')\n",
    "    if inference_params['ndvi']:\n",
    "        print('RUNNING INFERENCE INCLUDING NDVI CALCULATIONS')\n",
    "    if inference_params['residential'] or inference_params['ndvi']:\n",
    "        print('---------------------------------------------------------------------')\n",
    "    \n",
    "\n",
    "    #iterate through data, append to data dictionary \n",
    "    for i in zipcode_list:\n",
    "        for j in list(inference_images.items()):\n",
    "            image_name = j[0]\n",
    "            im = j[1]\n",
    "            if residential:\n",
    "                im = im.clip(residential_shape)\n",
    "            imagery = im.select(BANDS).classify(clf)\n",
    "            name = j[0]\n",
    "\n",
    "            start = time()\n",
    "            polygon = zipcode_shape.filter(ee.Filter.eq('ZipCode', i))\n",
    "            \n",
    "            dictionary['year'].append(image_name[:4]) \n",
    "            dictionary['polygon'].append(i)\n",
    "\n",
    "            water_area = area_calculation(imagery, 0, polygon, 20)\n",
    "            dictionary['water_area'].append(water_area)\n",
    "\n",
    "            vegetation_trees_area = area_calculation(imagery, 1, polygon, 20)\n",
    "            dictionary['vegetation_trees_area'].append(vegetation_trees_area)\n",
    "\n",
    "            vegetation_grass_area = area_calculation(imagery, 2, polygon, 20)\n",
    "            dictionary['vegetation_grass_area'].append(vegetation_grass_area)\n",
    "\n",
    "            turf_area = area_calculation(imagery, 3, polygon, 20)\n",
    "            dictionary['turf_area'].append(turf_area)\n",
    "\n",
    "            impervious_area = area_calculation(imagery, 4, polygon, 20)\n",
    "            dictionary['impervious_area'].append(impervious_area)\n",
    "\n",
    "            soil_area = area_calculation(imagery, 5, polygon, 20)\n",
    "            dictionary['soil_area'].append(soil_area)\n",
    "\n",
    "            total_area = water_area + vegetation_trees_area + vegetation_grass_area + turf_area + impervious_area + soil_area\n",
    "            dictionary['total_area'].append(total_area)\n",
    "            \n",
    "            if ndvi:\n",
    "                tree_ndvi_mean, tree_ndvi_max, tree_ndvi_min = ndvi_calculation(imagery, 1, polygon, ref_image = im).getInfo().values()\n",
    "                dictionary['tree_ndvi_mean'].append(tree_ndvi_mean)\n",
    "                dictionary['tree_ndvi_max'].append(tree_ndvi_max)\n",
    "                dictionary['tree_ndvi_min'].append(tree_ndvi_min)\n",
    "\n",
    "                grass_ndvi_mean, grass_ndvi_max, grass_ndvi_min = ndvi_calculation(imagery, 2, polygon, ref_image = im).getInfo().values()\n",
    "                dictionary['grass_ndvi_mean'].append(grass_ndvi_mean)\n",
    "                dictionary['grass_ndvi_max'].append(grass_ndvi_max)\n",
    "                dictionary['grass_ndvi_min'].append(grass_ndvi_min)\n",
    "\n",
    "\n",
    "\n",
    "            end = time()\n",
    "            print(f'Zip Code: {i}, Year: {j[0][:4]} ::: completed in {end-start} seconds.')\n",
    "        \n",
    "            insert_panel_zipcode(j[0][:4], i, water_area, vegetation_trees_area, vegetation_grass_area, \n",
    "                             turf_area, impervious_area, soil_area, total_area,\n",
    "                            tree_ndvi_mean, tree_ndvi_max, tree_ndvi_min,\n",
    "                            grass_ndvi_mean, grass_ndvi_max, grass_ndvi_min) \n",
    "\n",
    "    return dictionary\n",
    "              \n",
    "              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "dfdc1909",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_params = {\n",
    "        'source_image_collection' : 'USDA/NAIP/DOQQ',\n",
    "        'years' : [2010, 2012, 2014, 2016, 2018,2020],\n",
    "#        'zipcodes': ['90802','90732'],\n",
    "        'zipcodes': zipcode_list,\n",
    "        'ndvi': True,\n",
    "        'residential': False,\n",
    "        'residential_shape': la_parcel_res, #don't adjust this line\n",
    "        'counties': {'la_county': la_county}, #don't adjust this line\n",
    "        'zipcode_shape' : la_county_income_zipcode #don't adjust\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5595d8ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING INFERENCE INCLUDING NDVI CALCULATIONS\n",
      "---------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "dictionary = run_inference(inference_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a486ed28",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(dictionary)\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
