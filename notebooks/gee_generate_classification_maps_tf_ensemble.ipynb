{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f75d3c3",
   "metadata": {},
   "source": [
    "# Google Earth Engine Panel Data Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7c2826",
   "metadata": {},
   "source": [
    "## Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9aa63fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install geemap\n",
    "#!pip install ee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c0b302c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install uszipcode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03eb7500",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GEE specific\n",
    "import ee\n",
    "import geemap\n",
    "import math\n",
    "\n",
    "#plotting and functions\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "from time import time\n",
    "from enum import Enum\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c71c57c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize Google Earth Engine\n",
    "#ee.Authenticate() #just needed the 1st time\n",
    "ee.Initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d6a59409",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ccc71851c52484eb04485275b917181",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[20, 0], controls=(WidgetControl(options=['position', 'transparent_bg'], widget=HBox(children=(Togg…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check if geemap is working as intended - plot the leaflet map\n",
    "Map = geemap.Map()\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c3e5ac",
   "metadata": {},
   "source": [
    "## [OLD] Machine Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "36351661",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define classes\n",
    "CLASSES = ['water',\n",
    "           'vegetation_trees',\n",
    "           'vegetation_grass',\n",
    "           'turf',\n",
    "           'impervious',\n",
    "           'soil']\n",
    "\n",
    "OLD_CLASSES = ['water_pools'] + CLASSES[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "90fe5e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change classes to include lakes\n",
    "NEW_CLASSES = OLD_CLASSES + ['water_natural']\n",
    "NEW_CLASSES[0] = 'water_pools'\n",
    "\n",
    "# Define the  bands\n",
    "NBANDS = ['R', \n",
    "         'G', \n",
    "         'B', \n",
    "         'N', \n",
    "         'NDVI',\n",
    "         'N_Entropy', \n",
    "         'N_Contrast', \n",
    "         'N_Gearys']\n",
    "\n",
    "ALL_BANDS = NBANDS + ['R_Entropy',\n",
    "                      'R_Contrast',\n",
    "                      'R_Gearys',\n",
    "                      'G_Entropy',\n",
    "                      'G_Contrast',\n",
    "                      'G_Gearys',\n",
    "                      'B_Entropy',\n",
    "                      'B_Contrast',\n",
    "                      'B_Gearys']\n",
    "\n",
    "# Select desired band set\n",
    "BANDS = NBANDS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "965bfc2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_3bands(image, band):\n",
    "    i_8_bit = image.select(band).toUint8()\n",
    "    square = ee.Kernel.square(**{'radius': 4})\n",
    "    entropy = i_8_bit.entropy(square)\n",
    "    glcm = i_8_bit.glcmTexture(**{'size': 4})\n",
    "    contrast = glcm.select(str(band)+'_contrast')\n",
    "    \n",
    "    # Create a list of weights for a 9x9 kernel.\n",
    "    list = [1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
    "    # The center of the kernel is zero.\n",
    "    centerList = [1, 1, 1, 1, 0, 1, 1, 1, 1]\n",
    "    # Assemble a list of lists: the 9x9 kernel weights as a 2-D matrix.\n",
    "    lists = [list, list, list, list, centerList, list, list, list, list]\n",
    "    # Create the kernel from the weights.\n",
    "    # Non-zero weights represent the spatial neighborhood.\n",
    "    kernel = ee.Kernel.fixed(9, 9, lists, -4, -4, False)\n",
    "    neighs = i_8_bit.neighborhoodToBands(kernel)\n",
    "    gearys = i_8_bit.subtract(neighs).pow(2).reduce(ee.Reducer.sum()).divide(math.pow(9, 2))\n",
    "    image = image.addBands(entropy.rename(str(band)+'_Entropy')).addBands(contrast.rename(str(band)+'_Contrast')).addBands(gearys.rename(str(band)+'_Gearys'))   \n",
    "    return image\n",
    "\n",
    "def add_neighborhood_bands(image):\n",
    "    bands = ['R', 'G', 'B', 'N']\n",
    "    for band in bands:\n",
    "        image = apply_3bands(image, band)\n",
    "    return image\n",
    "    \n",
    "def add_NDVI(image):\n",
    "    image = image.addBands(image.normalizedDifference(['N','R']).rename('NDVI'))\n",
    "    return image\n",
    "\n",
    "def get_images(param_dict):\n",
    "    source_image_collection = param_dict['source_image_collection']\n",
    "    years = param_dict['years']\n",
    "    counties = param_dict['counties']\n",
    "\n",
    "    image_names = []\n",
    "    images = []\n",
    "\n",
    "    combos = list(itertools.product(years, counties.keys()))\n",
    "    for i in combos:\n",
    "        year = str(i[0])\n",
    "        county = i[1]\n",
    "\n",
    "        image_name = str(i[0])+'_'+i[1]\n",
    "        image_names.append(image_name)\n",
    "\n",
    "        image = ee.ImageCollection(source_image_collection)\\\n",
    "                                .filterDate(f'{year}-01-01', f'{year}-12-31')\\\n",
    "                                .select(['R','G','B','N'])\\\n",
    "                                .median().clip(counties[county])\n",
    "        images.append(image)\n",
    "        images_with_3band = list(map(add_neighborhood_bands, images))\n",
    "        images_with_NDVI = list(map(add_NDVI, images_with_3band))\n",
    "    return dict(zip(image_names, images_with_NDVI))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c9843f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_TF_classified_image(image, bands, tf_model, classes, name='classification'):\n",
    "    \n",
    "    '''\n",
    "    Use a TF model hosted on Google AI Platform to classify an EE image.\n",
    "    '''\n",
    "    \n",
    "    # Select bands from training image for classification\n",
    "    selected_image = image.select(bands)\n",
    "\n",
    "    # Get the predictions\n",
    "    predictions = tf_model.predictImage(selected_image.float().toArray())\n",
    "    probabilities = predictions.arrayFlatten([classes])\n",
    "    classified_image = predictions.arrayArgmax().arrayGet([0]).rename(name)\n",
    "    \n",
    "    return classified_image, predictions, probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "838b9049",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ensembled_classified_image(image, bands, model_dicts):\n",
    "    \n",
    "    \"\"\"\n",
    "    Get the ensembled classified image by getting the max prediction probability\n",
    "    for each pixel across all models. \n",
    "    \n",
    "    Each dict in model_dicts should contain the following keys for a particular model:\n",
    "        'model': the ee.Model object\n",
    "        'classes': the classes that the model will try to predict\n",
    "        'image_name': the name of the classified image from the model \n",
    "    \"\"\"\n",
    "    \n",
    "    output_images = []\n",
    "    combined_probs = None\n",
    "    \n",
    "    for model_dict in model_dicts:\n",
    "        # Unpack the model metadata\n",
    "        model = model_dict['model']\n",
    "        classes = model_dict['classes']\n",
    "        image_name = model_dict['image_name']\n",
    "        \n",
    "        # Predict on classified image\n",
    "        temp_image, temp_preds, temp_probs = get_TF_classified_image(image, bands, model, classes, name=image_name)\n",
    "        \n",
    "        # If no combined_probs set, set it to temp_probs\n",
    "        if combined_probs is None:\n",
    "            combined_probs = temp_probs\n",
    "        \n",
    "        # Check if classes are not the same, then add missing bands \n",
    "        cur_prob_bands = set(combined_probs.bandNames().getInfo())\n",
    "        add_cur_bands = list(cur_prob_bands - set(classes))\n",
    "        add_new_bands = list(set(classes) - cur_prob_bands)\n",
    "        \n",
    "        if add_cur_bands:\n",
    "            temp_probs = temp_probs.addBands(combined_probs, add_cur_bands)\n",
    "        if add_new_bands:\n",
    "            combined_probs = combined_probs.addBands(temp_probs, add_new_bands)\n",
    "        \n",
    "        # Get the max probs across the two images\n",
    "        combined_probs = combined_probs.max(temp_probs)\n",
    "        output_images.append(temp_image)\n",
    "    \n",
    "    # Get the final combined classification image based on maximum probabilities\n",
    "    classified_image = combined_probs.toArray().arrayArgmax().arrayGet([0]).rename('combined_classification')\n",
    "    output_images.append(classified_image)\n",
    "    \n",
    "    return output_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a3c86739",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_image_params = {\n",
    "        'source_image_collection' : 'USDA/NAIP/DOQQ',\n",
    "        'years' : [2020],\n",
    "        'counties': {'la_county': la_county}\n",
    "         }\n",
    "\n",
    "TRAINING_IMAGE = get_images(training_image_params)['2020_la_county']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9e79ed5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Map = geemap.Map()\n",
    "\n",
    "Map.addLayer(TRAINING_IMAGE, {}, 'NAIP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ef994138",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Point to the TF model(s) to be used for inference\n",
    "PROJECT = 'w210-351617'\n",
    "VERSION_NAME = 'v0'\n",
    "OLD_MODEL_NAME = 'CNN_Nbands_model'\n",
    "NEW_MODEL_NAME = 'CNN_Nbands_sep_cls_wlake_model'\n",
    "\n",
    "input_dim = [12,12]\n",
    "\n",
    "# Point to the old model hosted on AI Platform.\n",
    "old_tf_model = ee.Model.fromAiPlatformPredictor(\n",
    "    projectName=PROJECT,\n",
    "    modelName=OLD_MODEL_NAME,\n",
    "    version=VERSION_NAME,\n",
    "    # Can be anything, but don't make it too big.\n",
    "    inputTileSize=input_dim,\n",
    "    # Note the names here need to match what was specified in the\n",
    "    # output dictionary passed to the EEifier originally\n",
    "    outputBands={'output': {\n",
    "        'type': ee.PixelType.float(),\n",
    "        'dimensions': 1\n",
    "      }\n",
    "    },\n",
    ")\n",
    "\n",
    "# Point to the old model hosted on AI Platform.\n",
    "new_tf_model = ee.Model.fromAiPlatformPredictor(\n",
    "    projectName=PROJECT,\n",
    "    modelName=NEW_MODEL_NAME,\n",
    "    version=VERSION_NAME,\n",
    "    # Can be anything, but don't make it too big.\n",
    "    inputTileSize=input_dim,\n",
    "    # Note the names here need to match what was specified in the\n",
    "    # output dictionary passed to the EEifier originally\n",
    "    outputBands={'output': {\n",
    "        'type': ee.PixelType.float(),\n",
    "        'dimensions': 1\n",
    "      }\n",
    "    },\n",
    ")\n",
    "\n",
    "model_dicts = [\n",
    "    {'model': old_tf_model, 'classes': OLD_CLASSES, 'image_name':'old_classification'},\n",
    "    {'model': new_tf_model, 'classes': NEW_CLASSES, 'image_name':'new_classification'},\n",
    "]\n",
    "\n",
    "# Classify the training image per model + ensembled\n",
    "classified_images = get_ensembled_classified_image(TRAINING_IMAGE, BANDS, model_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cb690a11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<ee.image.Image at 0x7f848eb5de80>,\n",
       " <ee.image.Image at 0x7f848eb7f7c0>,\n",
       " <ee.image.Image at 0x7f848eb7f4c0>]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classified_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "be72a509",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5faee887f1a4397a49b30b0bd0dc255",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[20, 0], controls=(WidgetControl(options=['position', 'transparent_bg'], widget=HBox(children=(Togg…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Remap the combined image so lakes are classified as pools together\n",
    "fromList = [0, 1, 2, 3, 4, 5, 6]\n",
    "toList = [0, 1, 2, 3, 4, 5, 0]\n",
    "\n",
    "classified_images[-1] = classified_images[-1].remap(fromList, toList)\n",
    "\n",
    "old_legend_colors = ['#0B6AEF', '#097407', '#0CE708', '#8C46D2' ,' #A1A8AF','#D47911']\n",
    "new_legend_colors = ['#0B6AEF', '#097407', '#0CE708', '#8C46D2' ,' #A1A8AF','#D47911', '#191970']\n",
    "\n",
    "\n",
    "#water: #0B6AEF\n",
    "#trees dark green #097407\n",
    "#grass light green #0CE708\n",
    "#turf purple #8C46D2\n",
    "#impervious grey #A1A8AF\n",
    "#soil: orange #D47911\n",
    "\n",
    "\n",
    "colors_list = [old_legend_colors, new_legend_colors, old_legend_colors]\n",
    "\n",
    "for colors, image in zip(colors_list, classified_images):\n",
    "    layer_name = image.getInfo()['bands'][0]['id']\n",
    "    Map.addLayer(image, {'min': 0, 'max': len(colors)-1, 'palette': colors}, layer_name)\n",
    "\n",
    "Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1961e590",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "857bf9809b5449bb8a529e662a62b716",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[20, 0], controls=(WidgetControl(options=['position', 'transparent_bg'], widget=HBox(children=(Togg…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7575e49b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
